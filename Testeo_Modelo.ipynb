{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac75475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Testeo_Modelo.quick_test_model import quick_test_model\n",
    "import sys\n",
    "from Archivos_Apoyo.simple_log_redirect import init_simple_logging, log_print, both_print\n",
    "# Permitir especificar duraci√≥n como argumento\n",
    "duration = 30\n",
    "# INICIALIZAR LOGGING SIMPLE (1 L√çNEA)\n",
    "logger = init_simple_logging()\n",
    "# Viendo esto veo que best_model est√° mas aplicado ya que single_leg_balance_pam_final es capaz de mantener el equilibrio y best no\n",
    "model_path = \"./models_lift_leg/best_model.zip\"\n",
    "i=0\n",
    "model_path_checkpoint=\"models_lift_leg\\checkpoints\\single_leg_balance_pam_checkpoint_100000_steps.zip\"\n",
    "quick_test_model( duration=duration)\n",
    "logger.close()  # CERRAR AL FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e4ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "EP 1: return=-9089.0 | len=364 | reason=fall\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "EP 2: return=-7933.1 | len=364 | reason=fall\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "EP 3: return=-6777.3 | len=364 | reason=fall\n",
      "üîÑ Single leg balance environment reset - Ready for training\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTesteo_Modelo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_march_in_place\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_test\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobot_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2_legged_human_like_robot20DOF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels_lift_leg\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msingle_leg_balance_pam_final.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43msimple_reward_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwalk3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\Documents\\Master_IA\\TFM\\soft_robots\\programacion_soft_robotic\\Marcha_IK\\Testeo_Modelo\\test_march_in_place.py:50\u001b[0m, in \u001b[0;36mrun_test\u001b[1;34m(episodes, render, max_steps, best_model, robot_name, simple_reward_mode)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[0;32m     47\u001b[0m     action, state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     48\u001b[0m         obs, state\u001b[38;5;241m=\u001b[39mstate, episode_start\u001b[38;5;241m=\u001b[39mepisode_starts, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     )\n\u001b[1;32m---> 50\u001b[0m     obs, reward, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     episode_starts \u001b[38;5;241m=\u001b[39m dones\n\u001b[0;32m     52\u001b[0m     ep_ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(reward[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\GymnasiumBipedRobot\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\GymnasiumBipedRobot\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py:181\u001b[0m, in \u001b[0;36mVecNormalize.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Apply sequence of actions to sequence of environments\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    actions -> (observations, rewards, dones)\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    where ``dones`` is a boolean vector indicating whether each element is new.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m))  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mold_obs \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\GymnasiumBipedRobot\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\Documents\\Master_IA\\TFM\\soft_robots\\programacion_soft_robotic\\Marcha_IK\\Gymnasium_Start\\Simple_Lift_Leg_BipedEnv.py:255\u001b[0m, in \u001b[0;36mSimple_Lift_Leg_BipedEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    250\u001b[0m system_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESSIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m#if self.simple_reward_system:\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# Joint indices [0,1,2,4,5,6]\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint_states_properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtener_estado_articulaciones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_reward_system\u001b[38;5;241m.\u001b[39mis_episode_done(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count)\n\u001b[0;32m    258\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_reward_system\u001b[38;5;241m.\u001b[39mcalculate_reward(u_final, torque_mapping, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\Documents\\Master_IA\\TFM\\soft_robots\\programacion_soft_robotic\\Marcha_IK\\Gymnasium_Start\\Simple_Lift_Leg_BipedEnv.py:290\u001b[0m, in \u001b[0;36mSimple_Lift_Leg_BipedEnv.obtener_estado_articulaciones\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobtener_estado_articulaciones\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 290\u001b[0m     joint_states \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetJointStates\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobot_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoint_indices\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# s√≥lo 8 DOF controlados\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_hip_roll_angle \u001b[38;5;241m=\u001b[39m joint_states[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_hip_pitch_angle \u001b[38;5;241m=\u001b[39m joint_states[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "from Testeo_Modelo.test_march_in_place import run_test\n",
    "\n",
    "run_test(episodes=5, render=True, robot_name=\"2_legged_human_like_robot20DOF\", best_model= \"models_lift_leg\\single_leg_balance_pam_final.zip\",\n",
    "         simple_reward_mode='walk3d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GymnasiumBipedRobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
