#!/usr/bin/env python3
"""
TEST DE ACCIONES EXPERTAS
Verificar que el robot puede balancearse usando el controlador experto antes del entrenamiento.
"""

import numpy as np
import time
from Gymnasium_Start.Simple_BalanceSquat_BipedEnv import create_simple_balance_squat_env
from Controlador.discrete_action_controller import create_balance_squat_controller, ActionType

def test_expert_balance(duration_seconds=30, render=True):
    """
    Test del comportamiento experto de balance por 30 segundos
    """
    
    print("ğŸ¯ TESTING EXPERT BALANCE BEHAVIOR")
    print("="*50)
    print("Objetivo: Verificar que el robot puede mantener balance usando acciones expertas")
    print(f"DuraciÃ³n: {duration_seconds} segundos")
    print("="*50)
    
    # Crear entorno con visualizaciÃ³n si se desea
    env = create_simple_balance_squat_env(render_mode='human' if render else 'direct')
    controller = create_balance_squat_controller(env)
    
    # Configurar para balance estÃ¡tico
    controller.set_action(ActionType.BALANCE_STANDING)
    
    # Reset
    obs, info = env.reset()
    
    # MÃ©tricas de seguimiento
    total_reward = 0
    step_count = 0
    rewards_history = []
    falls = 0
    
    steps_total = int(duration_seconds / env.time_step)
    
    print(f"\nğŸ¤– Iniciando test de balance experto...")
    print(f"   Time step: {env.time_step:.4f}s")
    print(f"   Total steps: {steps_total}")
    
    try:
        for step in range(steps_total):
            # Obtener acciÃ³n experta del controlador
            expert_action = controller.get_expert_action(env.time_step)
            
            # Ejecutar acciÃ³n
            obs, reward, done, truncated, info = env.step(expert_action)
            
            # Trackear mÃ©tricas
            total_reward += reward
            step_count += 1
            rewards_history.append(reward)
            
            # Mostrar progreso cada 3 segundos (aprox)
            if step % (int(3.0 / env.time_step)) == 0:
                current_time = step * env.time_step
                avg_reward = np.mean(rewards_history[-150:]) if len(rewards_history) >= 150 else np.mean(rewards_history)
                print(f"   t={current_time:5.1f}s | Steps: {step:4d} | Reward: {reward:6.2f} | Avg: {avg_reward:6.2f}")
            
            # Si el robot se cae, resetear
            if done:
                falls += 1
                print(f"   âš ï¸ Fall detected at t={step * env.time_step:.1f}s (Fall #{falls})")
                obs, info = env.reset()
                controller.set_action(ActionType.BALANCE_STANDING)  # Reconfigurar acciÃ³n
                
                # Si se cae demasiado, terminar early
                if falls >= 3:
                    print(f"   âŒ Too many falls ({falls}). Terminating test early.")
                    break
        
        env.close()
        
        # ===== ANÃLISIS DE RESULTADOS =====
        
        print(f"\nğŸ“Š EXPERT BALANCE TEST RESULTS:")
        print("="*50)
        
        # MÃ©tricas bÃ¡sicas
        actual_duration = step_count * env.time_step
        avg_reward = total_reward / step_count if step_count > 0 else 0
        
        print(f"â±ï¸  Duration: {actual_duration:.1f}s / {duration_seconds:.1f}s target")
        print(f"ğŸ‘Ÿ Steps completed: {step_count:,}")
        print(f"ğŸ¯ Total reward: {total_reward:.2f}")
        print(f"ğŸ“ˆ Average reward: {avg_reward:.3f}")
        print(f"ğŸ’” Falls: {falls}")
        
        # AnÃ¡lisis de estabilidad
        if len(rewards_history) > 100:
            recent_rewards = rewards_history[-100:]
            stability_score = np.mean(recent_rewards)
            print(f"ğŸ”„ Recent stability (last 100 steps): {stability_score:.3f}")
        
        # ===== EVALUACIÃ“N DEL DESEMPEÃ‘O =====
        
        print(f"\nğŸ¯ PERFORMANCE EVALUATION:")
        print("-"*30)
        
        # Criterios de Ã©xito
        success_criteria = {
            'duration': actual_duration >= duration_seconds * 0.8,  # Al menos 80% del tiempo
            'avg_reward': avg_reward > -5.0,  # Recompensa promedio razonable
            'falls': falls <= 1,  # MÃ¡ximo 1 caÃ­da
            'completion': step_count >= steps_total * 0.8  # Al menos 80% de steps
        }
        
        passed_criteria = sum(success_criteria.values())
        total_criteria = len(success_criteria)
        
        for criterion, passed in success_criteria.items():
            status = "âœ…" if passed else "âŒ"
            print(f"   {status} {criterion}")
        
        # Veredicto final
        if passed_criteria == total_criteria:
            verdict = "ğŸ‰ EXCELLENT"
            message = "Expert controller works perfectly! Ready for training."
        elif passed_criteria >= 3:
            verdict = "âœ… GOOD"
            message = "Expert controller works well. Training should be successful."
        elif passed_criteria >= 2:
            verdict = "âš ï¸ MODERATE"
            message = "Expert controller needs tuning. Training may be challenging."
        else:
            verdict = "âŒ POOR"
            message = "Expert controller failing. Fix before training."
        
        print(f"\n{verdict}")
        print(f"   Score: {passed_criteria}/{total_criteria}")
        print(f"   {message}")
        
        # Recomendaciones
        print(f"\nğŸ’¡ RECOMMENDATIONS:")
        if passed_criteria >= 3:
            print("   ğŸš€ Proceed with full training")
            print("   ğŸ“ˆ Use current expert actions for imitation learning")
            print("   âš™ï¸ Consider total_timesteps=500k-1M for first training")
        else:
            print("   ğŸ”§ Tune expert action patterns before training")
            print("   ğŸ“Š Check reward system weights")
            print("   ğŸ¯ Verify robot URDF and physics parameters")
        
        return {
            'success': passed_criteria >= 3,
            'score': passed_criteria / total_criteria,
            'avg_reward': avg_reward,
            'falls': falls,
            'duration': actual_duration,
            'verdict': verdict
        }
        
    except KeyboardInterrupt:
        print("\nâ¸ï¸ Test interrupted by user")
        env.close()
        return {'success': False, 'score': 0, 'interrupted': True}
    
    except Exception as e:
        print(f"\nğŸ’¥ Test failed with exception: {e}")
        env.close()
        return {'success': False, 'score': 0, 'error': str(e)}

def test_expert_squat(duration_seconds=20, render=True):
    """
    Test del comportamiento experto de sentadillas
    """
    
    print("\nğŸ‹ï¸ TESTING EXPERT SQUAT BEHAVIOR")
    print("="*50)
    print("Objetivo: Verificar que el robot puede hacer sentadillas usando acciones expertas")
    print(f"DuraciÃ³n: {duration_seconds} segundos")
    print("="*50)
    
    env = create_simple_balance_squat_env(render_mode='human' if render else 'direct')
    controller = create_balance_squat_controller(env)
    
    # Configurar para sentadillas
    controller.set_action(ActionType.SQUAT)
    
    obs, info = env.reset()
    
    total_reward = 0
    step_count = 0
    squat_cycles = 0
    
    steps_total = int(duration_seconds / env.time_step)
    
    print(f"\nğŸ‹ï¸ Iniciando test de sentadillas expertas...")
    
    try:
        for step in range(steps_total):
            expert_action = controller.get_expert_action(env.time_step)
            obs, reward, done, truncated, info = env.step(expert_action)
            
            total_reward += reward
            step_count += 1
            
            # Detectar ciclos de sentadilla completados
            controller_info = controller.get_current_action_info()
            if controller_info['progress'] >= 1.0:
                squat_cycles += 1
                print(f"   ğŸ‹ï¸ Squat cycle #{squat_cycles} completed at t={step * env.time_step:.1f}s")
            
            # Mostrar progreso
            if step % (int(4.0 / env.time_step)) == 0:
                current_time = step * env.time_step
                progress = controller_info['progress']
                phase = controller_info['current_phase']
                print(f"   t={current_time:5.1f}s | Phase: {phase}/3 | Progress: {progress:.1%} | Reward: {reward:6.2f}")
            
            if done:
                print(f"   âŒ Episode ended early at t={step * env.time_step:.1f}s")
                break
        
        env.close()
        
        print(f"\nğŸ“Š EXPERT SQUAT TEST RESULTS:")
        print(f"   ğŸ‹ï¸ Squat cycles completed: {squat_cycles}")
        print(f"   ğŸ¯ Average reward: {total_reward / step_count:.3f}")
        print(f"   â±ï¸ Duration: {step_count * env.time_step:.1f}s")
        
        if squat_cycles >= 1:
            print(f"   âœ… Squat controller working!")
        else:
            print(f"   âš ï¸ No complete squat cycles detected")
        
        return {'squat_cycles': squat_cycles, 'avg_reward': total_reward / step_count}
        
    except KeyboardInterrupt:
        print("\nâ¸ï¸ Squat test interrupted")
        env.close()
        return {'squat_cycles': 0, 'interrupted': True}

def run_expert_verification():
    """Ejecutar verificaciÃ³n completa de acciones expertas"""
    
    print("ğŸ¯ EXPERT ACTION VERIFICATION SUITE")
    print("="*60)
    print("Este test verifica que las acciones expertas funcionan antes del entrenamiento")
    print("="*60)
    
    # Test 1: Balance
    balance_results = test_expert_balance(duration_seconds=20, render=True)
    
    # Test 2: Sentadillas (solo si balance funciona bien)
    if balance_results.get('success', False):
        squat_results = test_expert_squat(duration_seconds=15, render=True)
    else:
        print("\nâš ï¸ Skipping squat test due to balance issues")
        squat_results = {'squat_cycles': 0}
    
    # Veredicto final
    print(f"\nğŸ¯ FINAL EXPERT VERIFICATION VERDICT:")
    print("="*50)
    
    if balance_results.get('success', False):
        if squat_results.get('squat_cycles', 0) >= 1:
            print("ğŸ‰ READY FOR TRAINING!")
            print("   âœ… Balance works")
            print("   âœ… Squats work")
            print("   ğŸš€ Proceed with train_balance_and_squats()")
        else:
            print("âœ… MOSTLY READY")
            print("   âœ… Balance works")
            print("   âš ï¸ Squats need tuning")
            print("   ğŸš€ Can start with balance-focused training")
    else:
        print("âš ï¸ NEEDS WORK")
        print("   âŒ Balance issues detected")
        print("   ğŸ”§ Fix expert controller before training")
    
    return balance_results, squat_results

if __name__ == "__main__":
    run_expert_verification()
