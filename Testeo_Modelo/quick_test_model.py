#!/usr/bin/env python3
"""
SCRIPT R√ÅPIDO: Prueba simple del modelo entrenado
Ejecuta el modelo y muestra si puede levantar las piernas
"""

import numpy as np
import time
import os
from sb3_contrib import RecurrentPPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from Gymnasium_Start.Simple_Lift_Leg_BipedEnv import Simple_Lift_Leg_BipedEnv

def quick_test_model(model_path= "./models_lift_leg/best_model.zip", duration=30):
    """
    Prueba r√°pida del modelo entrenado
    
    Args:
        duration: Duraci√≥n en segundos del test
    """
    
    print("üöÄ PRUEBA R√ÅPIDA DEL MODELO ENTRENADO")
    print("=" * 50)
    
    # Buscar modelo
    if not os.path.exists(model_path):
        # Buscar checkpoint m√°s reciente
        import glob
        checkpoints = glob.glob("./models_lift_leg/checkpoints/*_checkpoint_*.zip")
        if checkpoints:
            # Obtener el m√°s reciente por fecha de modificaci√≥n
            model_path = max(checkpoints, key=os.path.getmtime)
        else:
            print("‚ùå No se encontr√≥ modelo entrenado")
            print("üí° Ejecuta primero: python inicio_programa.py")
            return
    
    print(f"üìÇ Usando modelo: {os.path.basename(model_path)}")
    
    # Crear entorno
    print("üèóÔ∏è Creando entorno...")
    env = Simple_Lift_Leg_BipedEnv(
        render_mode='human',
        action_space="pam", 
        enable_curriculum=False
    )
    
    vec_env = DummyVecEnv([lambda: env])
    vec_env = VecNormalize(vec_env, norm_obs=True, training=False)
    
    # Cargar normalizaci√≥n si existe
    norm_path = "./models_lift_leg/single_leg_balance_pam_normalize.pkl"
    if os.path.exists(norm_path):
        print("üìä Cargando normalizaci√≥n...")
        try:
            vec_env = VecNormalize.load(norm_path, vec_env)
            vec_env.training = False
        except:
            print("‚ö†Ô∏è Error con normalizaci√≥n, usando b√°sica")
    
    # Cargar modelo
    print("üß† Cargando modelo...")
    try:
        model = RecurrentPPO.load(model_path, env=vec_env)
        print("‚úÖ Modelo cargado correctamente")
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        vec_env.close()
        return
    
    # Ejecutar test
    print(f"üéÆ Ejecutando test de {duration}s...")
    print("   Observa si el robot:")
    print("   ‚Ä¢ Mantiene equilibrio")
    print("   ‚Ä¢ Levanta piernas alternadamente")
    print("   ‚Ä¢ Se mantiene estable")
    print()
    
    obs = vec_env.reset()
    lstm_states = None
    
    start_time = time.time()
    step_count = 0
    rewards = []
    leg_lifts_detected = 0
    last_contacts = (True, True)
    
    try:
        while time.time() - start_time < duration:
            # Predecir acci√≥n
            action, lstm_states = model.predict(obs, state=lstm_states, deterministic=True)
            
            # Ejecutar
            obs, reward, done, info = vec_env.step(action)
            
            step_count += 1
            rewards.append(reward[0])
            
            # Detectar levantamiento de piernas
            current_contacts = env.contacto_pies
            if last_contacts != current_contacts:
                # Cambi√≥ el patr√≥n de contacto
                if (last_contacts[0] and last_contacts[1]) and not (current_contacts[0] and current_contacts[1]):
                    leg_lifts_detected += 1
                    print(f"   ü¶µ Pierna levantada detectada! (#{leg_lifts_detected})")
            last_contacts = current_contacts
            
            # Mostrar progreso cada 5s
            if step_count % 2000 == 0:
                elapsed = time.time() - start_time
                print(f"   ‚è±Ô∏è {elapsed:.0f}s - Altura: {env.pos[2]:.2f}m - Reward: {reward[0]:.1f}")
            
            if done[0]:
                print("   üõë Episodio terminado (robot se cay√≥)")
                break
                
    except KeyboardInterrupt:
        print("\n‚è∏Ô∏è Test interrumpido")
    
    # Resultados
    elapsed = time.time() - start_time
    avg_reward = np.mean(rewards) if rewards else 0
    
    print(f"\nüìä RESULTADOS:")
    print(f"   Duraci√≥n: {elapsed:.1f}s / {duration}s")
    print(f"   Pasos ejecutados: {step_count}")
    print(f"   Reward promedio: {avg_reward:.2f}")
    print(f"   Levantamientos detectados: {leg_lifts_detected}")
    
    # Evaluaci√≥n simple
    success = elapsed >= duration * 0.9 and avg_reward > 1.0
    
    if success:
        print("üéâ ¬°√âXITO! El modelo puede controlar las piernas")
        if leg_lifts_detected >= 2:
            print("   ‚úÖ Detect√≥ m√∫ltiples levantamientos de piernas")
        else:
            print("   ‚ö†Ô∏è Pocos levantamientos detectados")
    else:
        print("‚ö†Ô∏è El modelo necesita m√°s entrenamiento")
        if elapsed < duration * 0.5:
            print("   ‚Ä¢ Robot se cay√≥ muy pronto")
        if avg_reward < 1.0:
            print("   ‚Ä¢ Reward muy bajo")
    
    vec_env.close()
    print("\n‚úÖ Test completado")

if __name__ == "__main__":
    import sys
    
    # Permitir especificar duraci√≥n como argumento
    duration = 30
    if len(sys.argv) > 1:
        try:
            duration = int(sys.argv[1])
        except:
            print("‚ö†Ô∏è Duraci√≥n inv√°lida, usando 30s")
    
    quick_test_model(duration)
