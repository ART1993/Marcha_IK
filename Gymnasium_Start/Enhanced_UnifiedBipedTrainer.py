import os
import numpy as np
from sb3_contrib import RecurrentPPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv
from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, CallbackList
from stable_baselines3.common.monitor import Monitor
import torch
import glob
import re
from datetime import datetime
import json

# Import your environments
from Archivos_Apoyo.Generate_Prints import log_training_plan, error_load_model, \
                                info_latest_checkpoint, print_info_env_pam
from Gymnasium_Start.bided_pam_IK import PAMIKBipedEnv  # Entorno original
from Gymnasium_Start.Enhanced_PAMIKBipedEnv import Enhanced_PAMIKBipedEnv  # Nuevo entorno mejorado
from Archivos_Apoyo.Configuraciones_adicionales import cargar_posible_normalizacion, phase_trainig_preparations
from Curriculum_generator.Curriculum_Manager import ExpertCurriculumManager 

class Enhanced_UnifiedBipedTrainer:
    """
    Entrenador unificado mejorado para sistemas de robot b√≠pedo con m√∫sculos PAM antag√≥nicos.
    
    Esta versi√≥n mejorada del entrenador entiende la diferencia fundamental entre:
    - Sistemas de m√∫sculos simples (4 PAMs independientes)
    - Sistemas de m√∫sculos antag√≥nicos (6 PAMs coordinados biomec√°nicamente)
    
    Es como la diferencia entre entrenar a alguien para mover m√∫sculos individuales
    versus entrenar a un atleta para coordinar grupos musculares de manera natural.
    """
    
    def __init__(self, 
                 env_type='enhanced_pam',  # Nuevo tipo de entorno por defecto
                 total_timesteps=5000000,
                 n_envs=8,
                 learning_rate=3e-4,  # Ligeramente reducido para mayor estabilidad
                 use_wandb=False,
                 resume_from=None,
                 action_space="pam", 
                 enable_expert_curriculum=True,
                 system_version="enhanced",  # 'simple' o 'enhanced'
                 ):
        
        # ===== CONFIGURACI√ìN B√ÅSICA =====
        
        self.env_type = env_type
        self.action_space = action_space
        self.total_timesteps = total_timesteps
        self.n_envs = n_envs
        self.learning_rate = learning_rate
        self.use_wandb = use_wandb
        self.resume_from = resume_from
        self.enable_expert_curriculum = enable_expert_curriculum
        self.system_version = system_version
        
        # ===== VALIDACI√ìN DE CONFIGURACI√ìN =====
        
        self._validate_configuration()
        
        # ===== CONFIGURACI√ìN AVANZADA =====
        
        # Configurar curr√≠culo experto si est√° habilitado
        if self.enable_expert_curriculum:
            self.curriculum_manager = ExpertCurriculumManager(total_timesteps)
            print(f"üéì Expert curriculum enabled with {len(self.curriculum_manager.phases)} phases")
            print(f"   Optimized for {self.system_version} PAM system")
        else:
            self.curriculum_manager = None

        # Configurar el entorno y modelo seg√∫n el tipo de sistema
        self.configuracion_modelo_entrenamiento
        
        # M√©tricas espec√≠ficas para sistemas antag√≥nicos
        self.biomechanical_metrics = {
            'coordination_scores': [],
            'energy_efficiency': [],
            'coactivation_quality': [],
            'temporal_smoothness': [],
            'phase_transitions': []
        }
        
        # M√©tricas del curr√≠culo experto
        self.expert_metrics = {
            'imitation_losses': [],
            'phase_rewards': [],
            'expert_action_similarity': [],
            'phase_success_rates': []
        }
        
        print(f"ü§ñ Enhanced Biped Trainer initialized")
        print(f"   System: {self.system_version} ({self._get_muscle_count()} muscles)")
        print(f"   Environment: {self.env_type}")
        print(f"   Target timesteps: {self.total_timesteps:,}")

    def _validate_configuration(self):
        """
        Valida que la configuraci√≥n del entrenador sea coherente y funcional.
        
        Esta funci√≥n es como un "chequeo de salud" que verifica que todas las
        configuraciones sean compatibles entre s√≠ antes de comenzar el entrenamiento.
        Es especialmente importante cuando mezclamos sistemas simples y avanzados.
        """
        
        print("üîç Validating trainer configuration...")
        
        # Verificar compatibilidad entre env_type y system_version
        if self.env_type == 'enhanced_pam' and self.system_version == 'simple':
            print("‚ö†Ô∏è Warning: Using enhanced environment with simple system version")
            print("   Consider using system_version='enhanced' for best results")
        
        if self.env_type == 'pam' and self.system_version == 'enhanced':
            print("‚ö†Ô∏è Warning: Using simple environment with enhanced system version")
            print("   Consider using env_type='enhanced_pam' for full functionality")
        
        # Ajustar par√°metros seg√∫n el tipo de sistema
        if self.system_version == 'enhanced':
            # Sistemas antag√≥nicos requieren m√°s tiempo para converger
            if self.total_timesteps < 3000000:
                print("üí° Recommendation: Enhanced systems typically need 3M+ timesteps")
                print(f"   Current target: {self.total_timesteps:,} timesteps")
            
            # Sistemas antag√≥nicos se benefician de tasas de aprendizaje m√°s conservadoras
            if self.learning_rate > 5e-4:
                print("üí° Recommendation: Enhanced systems benefit from lower learning rates")
                print(f"   Consider reducing from {self.learning_rate} to 3e-4 or lower")
        
        # Verificar configuraci√≥n de entornos paralelos
        if self.n_envs > 8 and self.system_version == 'enhanced':
            print("üí° Recommendation: Start with fewer parallel environments for enhanced systems")
            print("   Enhanced systems require more computation per step")
        
        print("   ‚úÖ Configuration validation completed")

    def _get_muscle_count(self):
        """Retorna el n√∫mero de m√∫sculos seg√∫n el tipo de sistema"""
        return 6 if self.system_version == 'enhanced' else 4

    @property
    def configuracion_modelo_entrenamiento(self):
        """
        Configuraci√≥n del modelo de entrenamiento adaptada para sistemas antag√≥nicos.
        
        Esta funci√≥n establece todas las configuraciones espec√≠ficas que necesita
        cada tipo de sistema. Es como configurar diferentes programas de entrenamiento
        para atletas de diferentes niveles.
        """
        
        # Crear directorios base
        self.model_dir = "./models"
        self.logs_dir = "./logs"
        self.checkpoints_dir = os.path.join(self.model_dir, "checkpoints")
        os.makedirs(self.model_dir, exist_ok=True)
        os.makedirs(self.logs_dir, exist_ok=True)
        os.makedirs(self.checkpoints_dir, exist_ok=True)
        
        # ===== CONFIGURACIONES ESPEC√çFICAS POR SISTEMA =====
        
        if self.system_version == 'enhanced':
            # Configuraci√≥n optimizada para sistemas de 6 m√∫sculos antag√≥nicos
            self.env_configs = {
                'enhanced_pam': {
                    'env_class': Enhanced_PAMIKBipedEnv,
                    'clip_obs': 25.0,      # Observaciones m√°s complejas requieren m√°s rango
                    'clip_reward': 20.0,   # Recompensas biomec√°nicas pueden ser m√°s altas
                    'net_arch': dict(pi=[512, 512, 256], vf=[512, 512, 256]),  # Redes m√°s grandes
                    'model_prefix': 'biped_6pam_biomechanical_expert' if self.enable_expert_curriculum else 'biped_6pam_biomechanical',
                    'description': 'Enhanced 6-muscle antagonistic PAM system with biomechanical rewards'
                },
                'pam': {
                    'env_class': Enhanced_PAMIKBipedEnv,  # Usar enhanced incluso para 'pam'
                    'clip_obs': 25.0,
                    'clip_reward': 20.0,
                    'net_arch': dict(pi=[512, 512, 256], vf=[512, 512, 256]),
                    'model_prefix': 'biped_6pam_enhanced_expert' if self.enable_expert_curriculum else 'biped_6pam_enhanced',
                    'description': 'Enhanced 6-muscle PAM system (backward compatibility)'
                }
            }
        else:
            # Configuraci√≥n para sistemas simples (4 m√∫sculos)
            self.env_configs = {
                'pam': {
                    'env_class': PAMIKBipedEnv,
                    'clip_obs': 20.0,
                    'clip_reward': 15.0,
                    'net_arch': dict(pi=[256, 256, 128], vf=[256, 256, 128]),
                    'model_prefix': 'biped_4pam_simple_expert' if self.enable_expert_curriculum else 'biped_4pam_simple',
                    'description': 'Simple 4-muscle independent PAM system'
                }
            }
        
        # ===== INFORMACI√ìN DE ENTRENAMIENTO =====
        
        self.training_info = {
            'completed_timesteps': 0,
            'completed_phases': [],
            'last_checkpoint': None,
            'training_start_time': None,
            'total_training_time': 0,
            'system_version': self.system_version,
            'muscle_count': self._get_muscle_count(),
            'biomechanical_metrics_enabled': self.system_version == 'enhanced'
        }
        
        print(f"   üìä Model configuration loaded for {self.system_version} system")
        if self.system_version == 'enhanced':
            config = self.env_configs[self.env_type]
            print(f"   üß† Neural network architecture: {config['net_arch']}")
            print(f"   üìà Enhanced observation/reward clipping: {config['clip_obs']}/{config['clip_reward']}")

    def create_training_env(self):
        """
        Creaci√≥n de entorno de entrenamiento optimizado para sistemas antag√≥nicos.
        
        Esta funci√≥n ahora entiende las diferencias entre sistemas simples y avanzados,
        y configura el entorno apropiadamente. Es como seleccionar el gimnasio correcto
        para el tipo de entrenamiento que queremos hacer.
        """
        
        config = self.env_configs[self.env_type]
        env_class = config['env_class']
        
        print(f"üèóÔ∏è Creating training environment: {config['description']}")
        
        def make_env():
            def _init():
                # Crear el entorno con la configuraci√≥n apropiada
                env = env_class(
                    render_mode='human' if self.n_envs == 1 else 'direct', 
                    action_space=self.action_space
                )
                
                # Para sistemas enhanced, configurar m√©tricas biomec√°nicas
                if self.system_version == 'enhanced' and hasattr(env, 'reward_system_integration_status'):
                    env.reward_system_integration_status['trainer_version'] = 'enhanced'
                
                env = Monitor(env, self.logs_dir)
                return env
            return _init
        
        # Crear entornos paralelos con configuraci√≥n optimizada
        env = self.create_parallel_env(make_env=make_env, config=config)
        
        # Para sistemas enhanced, configurar walking cycles si aplica
        if self.system_version == 'enhanced':
            self._setup_enhanced_walking_cycles(env)
        
        return env
    
    def _setup_enhanced_walking_cycles(self, env_wrapper):
        """
        Configura walking cycles optimizados para sistemas de m√∫sculos antag√≥nicos.
        
        Los sistemas antag√≥nicos requieren patrones de marcha m√°s sofisticados
        que consideren la coordinaci√≥n entre m√∫sculos opuestos.
        """
        
        print("   üö∂ Configuring enhanced walking cycles for antagonistic muscles...")
        
        def setup_walking_cycle(env_wrapper):
            if hasattr(env_wrapper, 'envs'):
                for env in env_wrapper.envs:
                    base_env = env.env if hasattr(env, 'env') else env
                    if hasattr(base_env, 'set_walking_cycle'):
                        base_env.set_walking_cycle(True)
                        print("     ‚úÖ Enhanced walking cycle enabled for training env")
            else:
                if hasattr(env_wrapper, 'set_walking_cycle'):
                    env_wrapper.set_walking_cycle(True)

        setup_walking_cycle(env_wrapper)
    
    def create_eval_env(self):
        """
        Crear entorno de evaluaci√≥n con configuraci√≥n optimizada.
        
        El entorno de evaluaci√≥n debe usar exactamente la misma configuraci√≥n
        que el entorno de entrenamiento para que las m√©tricas sean comparables.
        """
        
        config = self.env_configs[self.env_type]
        env_class = config['env_class']
        
        def make_eval_env():
            def _init():
                env = env_class(render_mode='direct', action_space=self.action_space)
                env = Monitor(env, os.path.join(self.logs_dir, "eval"))
                return env
            return _init
        
        eval_env = DummyVecEnv([make_eval_env()])
        eval_env = VecNormalize(eval_env, 
                               norm_obs=True, 
                               norm_reward=True, 
                               clip_obs=config['clip_obs'], 
                               training=False)

        # Configurar walking cycles para evaluaci√≥n tambi√©n
        if self.system_version == 'enhanced':
            self._setup_enhanced_walking_cycles(eval_env)

        return eval_env
    
    def create_model(self, env, resume_path=None):
        """
        Crear modelo RecurrentPPO optimizado para sistemas antag√≥nicos.
        
        Los sistemas de m√∫sculos antag√≥nicos requieren arquitecturas de red
        m√°s sofisticadas y hiperpar√°metros ajustados para manejar la complejidad
        adicional de la coordinaci√≥n muscular.
        """
        
        # Intentar cargar modelo existente
        model = self.cargar_creacion_modelo(resume_path=resume_path, env=env)
        if model is not None:
            return model
        
        config = self.env_configs[self.env_type]
        
        print(f"üß† Creating new RecurrentPPO model for {self.system_version} system...")
        print(f"   Target: {self._get_muscle_count()} muscle coordination")
        
        # ===== ARQUITECTURA LSTM OPTIMIZADA =====
        
        if self.system_version == 'enhanced':
            # Sistemas antag√≥nicos requieren m√°s memoria temporal y capacidad de procesamiento
            policy_kwargs_lstm = {
                'lstm_hidden_size': 256,  # M√°s memoria para coordinaci√≥n temporal
                'n_lstm_layers': 2,       # Capas m√∫ltiples para patrones complejos
                'shared_lstm': False,     # LSTMs separados para policy y value
                'net_arch': config['net_arch']  # Arquitectura m√°s profunda
            }
            
            # Hiperpar√°metros optimizados para coordinaci√≥n muscular
            model_params = {
                'learning_rate': self.learning_rate,
                'gamma': 0.995,           # Horizonte m√°s largo para patrones temporales
                'max_grad_norm': 0.3,     # Gradientes m√°s conservadores
                'ent_coef': 0.005,        # Menos exploraci√≥n aleatoria
                'n_steps': 1024,          # M√°s pasos para patrones largos
                'batch_size': 256,        # Batches m√°s grandes para estabilidad
                'n_epochs': 8,            # M√°s √©pocas para convergencia
                'gae_lambda': 0.98,       # GAE optimizado para secuencias largas
                'clip_range': 0.15,       # Clipping m√°s conservador
                'vf_coef': 0.4,           # Balance policy-value ajustado
            }
        else:
            # Configuraci√≥n est√°ndar para sistemas simples
            policy_kwargs_lstm = {
                'lstm_hidden_size': 128,
                'n_lstm_layers': 1,
                'shared_lstm': False,
                'net_arch': config['net_arch']
            }
            
            model_params = {
                'learning_rate': self.learning_rate,
                'gamma': 0.99,
                'max_grad_norm': 0.5,
                'ent_coef': 0.01,
            }
        
        # ===== CREACI√ìN DEL MODELO =====
        
        model = RecurrentPPO(
            "MlpLstmPolicy",
            env,
            policy_kwargs=policy_kwargs_lstm,
            verbose=1,
            tensorboard_log=self.logs_dir,
            device='auto',
            **model_params
        )
        
        print(f"   ‚úÖ Model created with {policy_kwargs_lstm['lstm_hidden_size']} LSTM units")
        print(f"   üéØ Optimized for {self.system_version} muscle coordination patterns")
        
        return model
    
    def setup_callbacks(self, eval_env):
        """
        Configurar callbacks optimizados para sistemas antag√≥nicos.
        
        Los sistemas antag√≥nicos requieren monitoreo m√°s frecuente y m√©tricas
        m√°s sofisticadas para entender el progreso del entrenamiento.
        """
        
        config = self.env_configs[self.env_type]
        
        print("üîß Setting up enhanced callbacks for biomechanical training...")
        
        # ===== CHECKPOINT CALLBACK =====
        
        # Sistemas antag√≥nicos se benefician de checkpoints m√°s frecuentes
        checkpoint_freq = 8000 if self.system_version == 'enhanced' else 10000
        
        checkpoint_callback = CheckpointCallback(
            save_freq=checkpoint_freq,
            save_path=self.checkpoints_dir,
            name_prefix=f'{config["model_prefix"]}_checkpoint',
            verbose=1
        )
        
        # ===== EVALUATION CALLBACK =====
        
        # Evaluaci√≥n m√°s frecuente para sistemas complejos
        eval_freq = 4000 if self.system_version == 'enhanced' else 5000
        n_eval_episodes = 8 if self.system_version == 'enhanced' else 5
        
        eval_callback = EvalCallback(
            eval_env,
            best_model_save_path=self.model_dir,
            log_path=os.path.join(self.logs_dir, "eval"),
            eval_freq=eval_freq,
            deterministic=True,
            render=False,
            n_eval_episodes=n_eval_episodes,
            verbose=1
        )
        
        callbacks = [checkpoint_callback, eval_callback]
        
        # ===== CALLBACK BIOMEC√ÅNICO (solo para sistemas enhanced) =====
        
        if self.system_version == 'enhanced':
            biomechanical_callback = self._create_biomechanical_callback()
            callbacks.append(biomechanical_callback)
            print("   üìä Biomechanical metrics callback added")
        
        print(f"   ‚úÖ Callbacks configured (checkpoint every {checkpoint_freq:,} steps)")
        
        return CallbackList(callbacks)
    
    def _create_biomechanical_callback(self):
        """
        Crear callback especializado para monitorear m√©tricas biomec√°nicas.
        
        Este callback observa las m√©tricas espec√≠ficas de coordinaci√≥n muscular
        y las registra para an√°lisis posterior.
        """
        
        class BiomechanicalMetricsCallback:
            def __init__(self, trainer):
                self.trainer = trainer
                self.step_count = 0
                self.last_log_step = 0
                
            def on_step(self, locals_, globals_):
                self.step_count += 1
                
                # Log m√©tricas cada 1000 pasos
                if self.step_count - self.last_log_step >= 1000:
                    self._log_biomechanical_metrics(locals_, globals_)
                    self.last_log_step = self.step_count
                
                return True
            
            def _log_biomechanical_metrics(self, locals_, globals_):
                """Registrar m√©tricas biomec√°nicas espec√≠ficas"""
                try:
                    # Obtener informaci√≥n del entorno si est√° disponible
                    if 'infos' in locals_:
                        infos = locals_['infos']
                        
                        # Extraer m√©tricas biomec√°nicas de los infos
                        coordination_scores = []
                        energy_efficiency = []
                        
                        for info in infos:
                            if isinstance(info, dict):
                                if 'reward_components' in info:
                                    components = info['reward_components']
                                    if 'pam_efficiency' in components:
                                        energy_efficiency.append(components['pam_efficiency'])
                                
                                if 'reward_system_status' in info:
                                    # Aqu√≠ podr√≠amos extraer m√©tricas de coordinaci√≥n
                                    pass
                        
                        # Guardar m√©tricas en el trainer
                        if coordination_scores:
                            self.trainer.biomechanical_metrics['coordination_scores'].extend(coordination_scores)
                        if energy_efficiency:
                            self.trainer.biomechanical_metrics['energy_efficiency'].extend(energy_efficiency)
                        
                        # Log cada cierto tiempo
                        if len(self.trainer.biomechanical_metrics['energy_efficiency']) > 0:
                            recent_efficiency = np.mean(self.trainer.biomechanical_metrics['energy_efficiency'][-10:])
                            print(f"   üìä Recent energy efficiency: {recent_efficiency:.3f}")
                
                except Exception as e:
                    # No fallar el entrenamiento por errores de logging
                    pass
        
        return BiomechanicalMetricsCallback(self)
    
    def train(self, resume=True):
        """
        Ejecutar entrenamiento optimizado para sistemas antag√≥nicos.
        
        Este m√©todo coordina todo el proceso de entrenamiento, adapt√°ndose
        autom√°ticamente a las diferencias entre sistemas simples y antag√≥nicos.
        """
        
        config = self.env_configs[self.env_type]
        
        print(f"üöÄ Starting {self.system_version.upper()} biped training with RecurrentPPO (LSTM)...")
        print(f"   System: {config['description']}")
        print(f"   Target muscles: {self._get_muscle_count()}")
        
        # ===== PREPARACI√ìN DEL ENTRENAMIENTO =====
        
        resume_path, resume_timesteps, remaining_timesteps = self.prep_modelo_anterior(resume)
        if resume_path is None and remaining_timesteps is None:
            print("   ‚úÖ Training already completed!")
            return

        # ===== CREACI√ìN DE ENTORNOS =====
        
        train_env = self.create_training_env()
        eval_env = self.create_eval_env()
        
        # Cargar normalizaciones existentes si las hay
        train_env = cargar_posible_normalizacion(self.model_dir, resume_path, config, train_env)
        
        # ===== CREACI√ìN DEL MODELO =====
        
        model = self.create_model(train_env, resume_path)
        
        # ===== CONFIGURACI√ìN DE CALLBACKS =====
        
        callbacks = self.setup_callbacks(eval_env)
        
        # ===== REGISTRO DE INICIO =====
        
        self.training_info['training_start_time'] = datetime.now().isoformat()
        self.training_info['completed_timesteps'] = resume_timesteps
        
        print(f"\nüéØ Training Configuration Summary:")
        print(f"   Environment: {self.env_type} ({self.system_version})")
        print(f"   Parallel environments: {self.n_envs}")
        print(f"   Learning rate: {self.learning_rate}")
        print(f"   LSTM architecture: {model.policy.lstm_hidden_size} units")
        print(f"   Target timesteps: {remaining_timesteps:,}")
        print(f"   Expert curriculum: {'‚úÖ ENABLED' if self.enable_expert_curriculum else '‚ùå DISABLED'}")
        
        try:
            # ===== EJECUTAR ENTRENAMIENTO =====
            
            if self.enable_expert_curriculum:
                model, config, train_env, eval_env = self.seleccion_entrenamiento_fases(
                    resume_timesteps, config, callbacks, model, train_env, eval_env
                )
            else:
                # Entrenamiento tradicional sin curr√≠culo
                model.learn(
                    total_timesteps=remaining_timesteps,
                    callback=callbacks,
                    tb_log_name=f"{config['model_prefix']}_training",
                    reset_num_timesteps=(resume_timesteps == 0)
                )
                self.training_info['completed_timesteps'] = self.total_timesteps
            
            # ===== GUARDAR MODELO FINAL =====
            
            final_model_path = os.path.join(self.model_dir, f"{config['model_prefix']}_final")
            model.save(final_model_path)
            print(f"‚úÖ Final model saved at: {final_model_path}")
            
            # Guardar normalizaciones
            if isinstance(train_env, VecNormalize):
                norm_path = os.path.join(self.model_dir, f"{config['model_prefix']}_normalize.pkl")
                train_env.save(norm_path)
                print(f"‚úÖ Normalization saved at: {norm_path}")
            
            # ===== GUARDAR INFORMACI√ìN DE ENTRENAMIENTO =====
            
            self.save_enhanced_training_info()
            
            print(f"\nüéâ {self.system_version.upper()} training completed successfully!")
            if self.system_version == 'enhanced':
                print("   üìä Biomechanical metrics logged for analysis")
                self._print_final_biomechanical_summary()
                
        except KeyboardInterrupt:
            print("‚è∏Ô∏è Training interrupted by user")
            
        finally:
            train_env.close()
            eval_env.close()

    def _print_final_biomechanical_summary(self):
        """Imprimir resumen final de m√©tricas biomec√°nicas"""
        
        print("\nüìä BIOMECHANICAL TRAINING SUMMARY")
        print("=" * 50)
        
        if self.biomechanical_metrics['energy_efficiency']:
            avg_efficiency = np.mean(self.biomechanical_metrics['energy_efficiency'])
            print(f"   Average energy efficiency: {avg_efficiency:.3f}")
        
        if self.biomechanical_metrics['coordination_scores']:
            avg_coordination = np.mean(self.biomechanical_metrics['coordination_scores'])
            print(f"   Average coordination score: {avg_coordination:.3f}")
        
        print(f"   Total biomechanical samples: {len(self.biomechanical_metrics['energy_efficiency'])}")
        print("=" * 50)

    def save_enhanced_training_info(self):
        """
        Guardar informaci√≥n de entrenamiento mejorada con m√©tricas biomec√°nicas.
        """
        
        config = self.env_configs[self.env_type]
        info_path = os.path.join(self.model_dir, f"{config['model_prefix']}_training_info.json")
        
        training_data = {
            'environment': self.env_type,
            'system_version': self.system_version,
            'muscle_count': self._get_muscle_count(),
            'action_space': self.action_space,
            'completed_timesteps': self.training_info['completed_timesteps'],
            'total_timesteps_target': self.total_timesteps,
            'last_checkpoint': self.training_info['last_checkpoint'],
            'training_start': self.training_info['training_start_time'],
            'total_training_time_hours': self.training_info['total_training_time'],
            'n_envs': self.n_envs,
            'learning_rate': self.learning_rate,
            'expert_curriculum_enabled': self.enable_expert_curriculum
        }
        
        # A√±adir m√©tricas biomec√°nicas si est√°n disponibles
        if self.system_version == 'enhanced':
            training_data['biomechanical_metrics'] = {
                'samples_collected': len(self.biomechanical_metrics['energy_efficiency']),
                'avg_energy_efficiency': np.mean(self.biomechanical_metrics['energy_efficiency']) if self.biomechanical_metrics['energy_efficiency'] else 0.0,
                'avg_coordination': np.mean(self.biomechanical_metrics['coordination_scores']) if self.biomechanical_metrics['coordination_scores'] else 0.0,
            }
        
        # A√±adir informaci√≥n del curr√≠culo si est√° habilitado
        if self.enable_expert_curriculum and self.curriculum_manager:
            training_data['curriculum_info'] = {
                'total_phases': len(self.curriculum_manager.phases),
                'completed_phases': self.training_info.get('completed_phases', []),
                'phase_transitions': self.curriculum_manager.phase_transitions,
            }
        
        with open(info_path, 'w') as f:
            json.dump(training_data, f, indent=2)
        
        print(f"üíæ Enhanced training info saved to: {info_path}")

    # ===== M√âTODOS HEREDADOS CON MODIFICACIONES MENORES =====
    # (Los m√©todos restantes mantienen la funcionalidad existente pero con
    # peque√±os ajustes para sistemas antag√≥nicos)

    def cargar_creacion_modelo(self, resume_path, env):
        """Load existing model if available"""
        if resume_path and os.path.exists(resume_path):
            print(f"üîÑ Loading model from checkpoint: {resume_path}")
            try:
                model = RecurrentPPO.load(resume_path, env=env)
                
                if hasattr(model, 'learning_rate') and model.learning_rate != self.learning_rate:
                    print(f"üìù Updating learning rate: {model.learning_rate} -> {self.learning_rate}")
                    model.learning_rate = self.learning_rate
                    
                return model
            except Exception as e:
                error_load_model(e)
        return None

    def prep_modelo_anterior(self, resume):
        """Carga el modelo anterior teniendo en cuenta los timesteps restantes"""
        resume_path = None
        resume_timesteps = 0

        if resume and self.resume_from:
            if os.path.exists(self.resume_from):
                resume_path = self.resume_from
                match = re.search(r'_(\d+)_steps\.zip$', self.resume_from)
                if match:
                    resume_timesteps = int(match.group(1))
                print(f"üìÇ Resuming from specified checkpoint: {self.resume_from}")
            else:
                print(f"‚ö†Ô∏è Specified checkpoint not found: {self.resume_from}")
        elif resume:
            latest_checkpoint, resume_timesteps = self.find_latest_checkpoint()
            resume_path = info_latest_checkpoint(latest_checkpoint, resume_timesteps)
        
        remaining_timesteps = max(0, self.total_timesteps - resume_timesteps)
        log_training_plan(resume_timesteps, remaining_timesteps, self.total_timesteps)

        if remaining_timesteps == 0:
            print(f"‚úÖ Training already completed! ({resume_timesteps:,}/{self.total_timesteps:,} timesteps)")
            return None, None, None
        
        return resume_path, resume_timesteps, remaining_timesteps

    def find_latest_checkpoint(self, model_prefix=None):
        """Find the most recent checkpoint based on timesteps."""
        if model_prefix is None:
            model_prefix = self.env_configs[self.env_type]['model_prefix']
        
        checkpoint_pattern = os.path.join(self.checkpoints_dir, f"{model_prefix}_checkpoint_*_steps.zip")
        checkpoint_files = glob.glob(checkpoint_pattern)
        
        if not checkpoint_files:
            return None, 0
        
        timesteps = []
        for file in checkpoint_files:
            match = re.search(r'_(\d+)_steps\.zip$', file)
            if match:
                timesteps.append((int(match.group(1)), file))
        
        if not timesteps:
            return None, 0
        
        latest_timesteps, latest_file = max(timesteps, key=lambda x: x[0])
        return latest_file, latest_timesteps

    def create_parallel_env(self, make_env, config):
        """Creaci√≥n de entornos paralelos optimizada"""
        if self.n_envs > 1:
            base_env = SubprocVecEnv([make_env() for _ in range(self.n_envs)])
            env = VecNormalize(base_env, 
                             norm_obs=True, 
                             norm_reward=True, 
                             clip_obs=config['clip_obs'],
                             clip_reward=config['clip_reward'])
        else:
            base_env = DummyVecEnv([make_env()])
            env = VecNormalize(base_env, 
                             norm_obs=True, 
                             norm_reward=True, 
                             clip_obs=config['clip_obs'],
                             clip_reward=config['clip_reward'])

        return env

    def seleccion_entrenamiento_fases(self, resume_timesteps, config, callbacks, model,
                                      train_env, eval_env):
        """M√©todo de entrenamiento por fases (simplificado para brevedad)"""
        # Esta funci√≥n mantendr√≠a la l√≥gica existente pero optimizada para sistemas antag√≥nicos
        # Por brevedad, mantengo la estructura b√°sica
        
        if self.action_space == "pam":
            # Entrenamiento directo sin fases para sistemas PAM puros
            remaining_timesteps = max(0, self.total_timesteps - resume_timesteps)
            
            if remaining_timesteps > 0:
                model.learn(
                    total_timesteps=remaining_timesteps,
                    callback=callbacks,
                    tb_log_name=f"{config['model_prefix']}_direct_training",
                    reset_num_timesteps=(resume_timesteps == 0)
                )
            
            self.training_info['completed_timesteps'] = self.total_timesteps
        
        return model, config, train_env, eval_env


# ===== FUNCI√ìN DE CREACI√ìN F√ÅCIL =====

def create_enhanced_trainer(**kwargs):
    """
    Funci√≥n de conveniencia para crear un entrenador optimizado.
    
    Esta funci√≥n selecciona autom√°ticamente la mejor configuraci√≥n
    basada en los par√°metros proporcionados.
    """
    
    # Valores por defecto optimizados
    defaults = {
        'env_type': 'enhanced_pam',
        'system_version': 'enhanced',
        'total_timesteps': 5000000,
        'n_envs': 6,  # N√∫mero optimizado para sistemas antag√≥nicos
        'learning_rate': 3e-4,
        'action_space': 'pam',
        'enable_expert_curriculum': True
    }
    
    # Combinar defaults con argumentos del usuario
    config = {**defaults, **kwargs}
    
    print(f"üéØ Creating optimized trainer for {config['system_version']} system")
    
    return Enhanced_UnifiedBipedTrainer(**config)


# ===== EJEMPLOS DE USO =====

def train_enhanced_pam_biped(total_timesteps=5000000, n_envs=6, resume=True):
    """Funci√≥n de conveniencia para entrenar sistema antag√≥nico avanzado"""
    
    trainer = create_enhanced_trainer(
        total_timesteps=total_timesteps,
        n_envs=n_envs,
        system_version='enhanced',
        env_type='enhanced_pam'
    )
    
    print("üöÄ Starting enhanced antagonistic PAM training...")
    trainer.train(resume=resume)
    return trainer

def train_simple_pam_biped(total_timesteps=3000000, n_envs=4, resume=True):
    """Funci√≥n de conveniencia para entrenar sistema simple (backward compatibility)"""
    
    trainer = create_enhanced_trainer(
        total_timesteps=total_timesteps,
        n_envs=n_envs,
        system_version='simple',
        env_type='pam'
    )
    
    print("üöÄ Starting simple PAM training...")
    trainer.train(resume=resume)
    return trainer

# ===== FUNCI√ìN DE TESTING INTEGRAL =====

def test_enhanced_trainer_integration():
    """
    Funci√≥n integral de testing para validar la integraci√≥n completa del Enhanced_UnifiedBipedTrainer.
    
    Esta funci√≥n realiza un examen exhaustivo de todos los componentes cr√≠ticos del sistema,
    verificando paso a paso que cada elemento funciona correctamente y se comunica apropiadamente
    con los dem√°s. Es como un "chequeo m√©dico completo" para tu sistema de entrenamiento.
    
    La funci√≥n est√° dise√±ada para ser ejecutada desde un Jupyter notebook, proporcionando
    output detallado y educativo en cada paso del proceso de validaci√≥n.
    
    Returns:
        dict: Reporte completo del estado de integraci√≥n con detalles de cada test
    """
    
    print("üî¨ ENHANCED TRAINER INTEGRATION TEST")
    print("=" * 70)
    print("Esta funci√≥n verificar√° paso a paso que todos los componentes")
    print("del sistema antag√≥nico de 6 m√∫sculos PAM funcionen correctamente.")
    print("=" * 70)
    
    # Diccionario para almacenar resultados de cada test
    test_results = {
        'overall_status': 'UNKNOWN',
        'trainer_creation': {},
        'environment_creation': {},
        'model_creation': {},
        'integration_verification': {},
        'biomechanical_metrics': {},
        'errors': [],
        'warnings': [],
        'recommendations': []
    }
    
    try:
        # ===== TEST 1: CREACI√ìN B√ÅSICA DEL TRAINER =====
        
        print("\nüèóÔ∏è TEST 1: Creaci√≥n B√°sica del Trainer")
        print("-" * 50)
        print("Verificando que el Enhanced_UnifiedBipedTrainer se puede crear")
        print("correctamente con diferentes configuraciones...")
        
        try:
            # Test con configuraci√≥n enhanced (sistema antag√≥nico)
            print("\n   üìä Creando trainer para sistema enhanced (6 m√∫sculos antag√≥nicos)...")
            enhanced_trainer = create_enhanced_trainer(
                total_timesteps=10000,  # N√∫mero peque√±o para testing
                n_envs=1,              # Un solo entorno para simplicidad
                system_version='enhanced',
                env_type='enhanced_pam'
            )
            
            test_results['trainer_creation']['enhanced'] = '‚úÖ SUCCESS'
            print(f"      ‚úÖ Enhanced trainer creado exitosamente")
            print(f"      üìà Configuraci√≥n: {enhanced_trainer._get_muscle_count()} m√∫sculos")
            print(f"      üß† Arquitectura de red: {enhanced_trainer.env_configs['enhanced_pam']['net_arch']}")
            
            # Test con configuraci√≥n simple (para compatibilidad)
            print("\n   üìä Creando trainer para sistema simple (4 m√∫sculos independientes)...")
            simple_trainer = create_enhanced_trainer(
                total_timesteps=10000,
                n_envs=1,
                system_version='simple',
                env_type='pam'
            )
            
            test_results['trainer_creation']['simple'] = '‚úÖ SUCCESS'
            print(f"      ‚úÖ Simple trainer creado exitosamente")
            print(f"      üìà Configuraci√≥n: {simple_trainer._get_muscle_count()} m√∫sculos")
            
        except Exception as e:
            test_results['errors'].append(f"Trainer creation failed: {str(e)}")
            test_results['trainer_creation']['status'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en creaci√≥n del trainer: {e}")
            return test_results
        
        # ===== TEST 2: CREACI√ìN DE ENTORNOS =====
        
        print("\nüåç TEST 2: Creaci√≥n de Entornos")
        print("-" * 50)
        print("Verificando que los entornos de entrenamiento y evaluaci√≥n")
        print("se pueden crear y configurar apropiadamente...")
        
        try:
            print("\n   üèãÔ∏è Creando entorno de entrenamiento...")
            train_env = enhanced_trainer.create_training_env()
            
            # Verificar propiedades del entorno
            action_space_shape = train_env.action_space.shape
            observation_space_shape = train_env.observation_space.shape
            
            print(f"      ‚úÖ Entorno de entrenamiento creado")
            print(f"      üéÆ Action space: {action_space_shape}")
            print(f"      üëÅÔ∏è Observation space: {observation_space_shape}")
            
            # Verificar que es el entorno correcto
            expected_action_dim = 6 if enhanced_trainer.system_version == 'enhanced' else 4
            if action_space_shape[0] == expected_action_dim:
                print(f"      ‚úÖ Dimensi√≥n de acci√≥n correcta: {expected_action_dim} m√∫sculos")
                test_results['environment_creation']['action_space'] = '‚úÖ CORRECT'
            else:
                print(f"      ‚ö†Ô∏è Dimensi√≥n de acci√≥n inesperada: {action_space_shape[0]} (esperado: {expected_action_dim})")
                test_results['warnings'].append(f"Action space dimension mismatch")
            
            print("\n   üìä Creando entorno de evaluaci√≥n...")
            eval_env = enhanced_trainer.create_eval_env()
            print(f"      ‚úÖ Entorno de evaluaci√≥n creado")
            
            test_results['environment_creation']['status'] = '‚úÖ SUCCESS'
            
        except Exception as e:
            test_results['errors'].append(f"Environment creation failed: {str(e)}")
            test_results['environment_creation']['status'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en creaci√≥n de entornos: {e}")
            return test_results
        
        # ===== TEST 3: CREACI√ìN DEL MODELO =====
        
        print("\nüß† TEST 3: Creaci√≥n del Modelo RecurrentPPO")
        print("-" * 50)
        print("Verificando que el modelo LSTM se puede crear con la")
        print("arquitectura optimizada para m√∫sculos antag√≥nicos...")
        
        try:
            print("\n   ü§ñ Creando modelo RecurrentPPO...")
            model = enhanced_trainer.create_model(train_env, resume_path=None)
            
            # Verificar propiedades del modelo
            if hasattr(model.policy, 'lstm_hidden_size'):
                lstm_size = model.policy.lstm_hidden_size
                print(f"      ‚úÖ Modelo LSTM creado con {lstm_size} unidades")
                
                expected_lstm_size = 256 if enhanced_trainer.system_version == 'enhanced' else 128
                if lstm_size == expected_lstm_size:
                    print(f"      ‚úÖ Tama√±o LSTM correcto para sistema {enhanced_trainer.system_version}")
                    test_results['model_creation']['lstm_size'] = '‚úÖ CORRECT'
                else:
                    print(f"      ‚ö†Ô∏è Tama√±o LSTM inesperado: {lstm_size} (esperado: {expected_lstm_size})")
                    test_results['warnings'].append(f"LSTM size mismatch")
            
            print(f"      üìö Learning rate: {model.learning_rate}")
            print(f"      üéØ Device: {model.device}")
            
            test_results['model_creation']['status'] = '‚úÖ SUCCESS'
            
        except Exception as e:
            test_results['errors'].append(f"Model creation failed: {str(e)}")
            test_results['model_creation']['status'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en creaci√≥n del modelo: {e}")
            return test_results
        
        # ===== TEST 4: VERIFICACI√ìN DE INTEGRACI√ìN =====
        
        print("\nüîó TEST 4: Verificaci√≥n de Integraci√≥n")
        print("-" * 50)
        print("Verificando que todos los componentes se comunican")
        print("correctamente entre s√≠...")
        
        try:
            print("\n   üß™ Realizando test de reset del entorno...")
            
            # Test de reset - esto debe inicializar todo el sistema
            obs, info = train_env.reset()
            
            print(f"      ‚úÖ Reset exitoso")
            print(f"      üìä Observaci√≥n inicial shape: {obs.shape}")
            print(f"      üìã Info keys: {list(info.keys()) if isinstance(info, dict) else 'No dict info'}")
            
            # Test de step - verificar que una acci√≥n se puede ejecutar
            print("\n   üéÆ Realizando test de step con acci√≥n aleatoria...")
            action = train_env.action_space.sample()
            obs, reward, done, truncated, info = train_env.step(action)
            
            print(f"      ‚úÖ Step exitoso")
            print(f"      üèÜ Reward recibido: {reward}")
            print(f"      üéØ Episode done: {done}")
            
            # Verificar informaci√≥n biomec√°nica si est√° disponible
            if isinstance(info, dict) and len(info) > 0:
                if 'reward_components' in info:
                    components = info['reward_components']
                    print(f"      üìà Componentes de reward disponibles: {len(components)}")
                    
                    # Mostrar algunos componentes importantes
                    important_components = ['pam_efficiency', 'stability', 'progress']
                    for comp in important_components:
                        if comp in components:
                            print(f"         {comp}: {components[comp]:.3f}")
                
                if 'num_active_pams' in info:
                    print(f"      üí™ PAMs activos: {info['num_active_pams']}")
                
                test_results['integration_verification']['info_available'] = '‚úÖ YES'
            else:
                test_results['warnings'].append("No detailed info available from environment")
            
            test_results['integration_verification']['status'] = '‚úÖ SUCCESS'
            
        except Exception as e:
            test_results['errors'].append(f"Integration verification failed: {str(e)}")
            test_results['integration_verification']['status'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en verificaci√≥n de integraci√≥n: {e}")
            return test_results
        
        # ===== TEST 5: M√âTRICAS BIOMEC√ÅNICAS =====
        
        print("\nüìä TEST 5: M√©tricas Biomec√°nicas")
        print("-" * 50)
        print("Verificando que las m√©tricas biomec√°nicas espec√≠ficas")
        print("del sistema antag√≥nico funcionan correctamente...")
        
        try:
            # Ejecutar varios steps para generar datos
            print("\n   üèÉ Ejecutando 10 steps para generar m√©tricas...")
            
            biomechanical_data = []
            for step in range(10):
                action = train_env.action_space.sample()
                obs, reward, done, truncated, info = train_env.step(action)
                
                if isinstance(info, dict) and 'reward_components' in info:
                    biomechanical_data.append(info['reward_components'])
                
                if done.any() if hasattr(done, 'any') else done:
                    print(f"         Episode ended at step {step}, resetting...")
                    obs, info = train_env.reset()
            
            if biomechanical_data:
                print(f"      ‚úÖ M√©tricas biomec√°nicas recolectadas de {len(biomechanical_data)} steps")
                
                # Analizar m√©tricas espec√≠ficas
                if 'pam_efficiency' in biomechanical_data[0]:
                    pam_efficiencies = [data['pam_efficiency'] for data in biomechanical_data]
                    avg_efficiency = sum(pam_efficiencies) / len(pam_efficiencies)
                    print(f"      üìà Eficiencia PAM promedio: {avg_efficiency:.3f}")
                    
                    test_results['biomechanical_metrics']['pam_efficiency'] = f'{avg_efficiency:.3f}'
                
                if 'stability' in biomechanical_data[0]:
                    stabilities = [data['stability'] for data in biomechanical_data]
                    avg_stability = sum(stabilities) / len(stabilities)
                    print(f"      ‚öñÔ∏è Estabilidad promedio: {avg_stability:.3f}")
                    
                    test_results['biomechanical_metrics']['stability'] = f'{avg_stability:.3f}'
                
                test_results['biomechanical_metrics']['status'] = '‚úÖ SUCCESS'
                
            else:
                print(f"      ‚ö†Ô∏è No se recolectaron m√©tricas biomec√°nicas detalladas")
                test_results['warnings'].append("No detailed biomechanical metrics collected")
                test_results['biomechanical_metrics']['status'] = '‚ö†Ô∏è LIMITED'
            
        except Exception as e:
            test_results['errors'].append(f"Biomechanical metrics test failed: {str(e)}")
            test_results['biomechanical_metrics']['status'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en test de m√©tricas biomec√°nicas: {e}")
        
        # ===== TEST 6: CALLBACKS Y CONFIGURACI√ìN AVANZADA =====
        
        print("\n‚öôÔ∏è TEST 6: Callbacks y Configuraci√≥n Avanzada")
        print("-" * 50)
        print("Verificando que los callbacks biomec√°nicos y la")
        print("configuraci√≥n avanzada funcionan correctamente...")
        
        try:
            print("\n   üìû Creando callbacks...")
            callbacks = enhanced_trainer.setup_callbacks(eval_env)
            
            print(f"      ‚úÖ Callbacks creados exitosamente")
            print(f"      üìã N√∫mero de callbacks: {len(callbacks.callbacks) if hasattr(callbacks, 'callbacks') else 'N/A'}")
            
            # Verificar que existe callback biomec√°nico para sistema enhanced
            if enhanced_trainer.system_version == 'enhanced':
                biomech_callback_found = False
                if hasattr(callbacks, 'callbacks'):
                    for callback in callbacks.callbacks:
                        if 'Biomechanical' in str(type(callback)):
                            biomech_callback_found = True
                            break
                
                if biomech_callback_found:
                    print(f"      ‚úÖ Callback biomec√°nico encontrado")
                    test_results['integration_verification']['biomech_callback'] = '‚úÖ FOUND'
                else:
                    print(f"      ‚ö†Ô∏è Callback biomec√°nico no detectado claramente")
            
            test_results['integration_verification']['callbacks'] = '‚úÖ SUCCESS'
            
        except Exception as e:
            test_results['errors'].append(f"Callbacks test failed: {str(e)}")
            test_results['integration_verification']['callbacks'] = '‚ùå FAILED'
            print(f"      ‚ùå Error en test de callbacks: {e}")
        
        # ===== CLEANUP =====
        
        print("\nüßπ Limpieza de recursos...")
        try:
            train_env.close()
            eval_env.close()
            print("      ‚úÖ Entornos cerrados correctamente")
        except:
            print("      ‚ö†Ô∏è Advertencia: problema cerrando entornos")
        
        # ===== EVALUACI√ìN FINAL =====
        
        print("\nüìã EVALUACI√ìN FINAL")
        print("=" * 50)
        
        # Determinar estado general
        error_count = len(test_results['errors'])
        warning_count = len(test_results['warnings'])
        
        if error_count == 0:
            if warning_count <= 2:
                test_results['overall_status'] = 'EXCELLENT'
                status_emoji = 'üéâ'
                status_message = "¬°Sistema completamente funcional y optimizado!"
            else:
                test_results['overall_status'] = 'GOOD'
                status_emoji = '‚úÖ'
                status_message = "Sistema funcional con algunas optimizaciones recomendadas"
        elif error_count <= 2:
            test_results['overall_status'] = 'FUNCTIONAL_WITH_ISSUES'
            status_emoji = '‚ö†Ô∏è'
            status_message = "Sistema funcional pero requiere atenci√≥n"
        else:
            test_results['overall_status'] = 'CRITICAL_ISSUES'
            status_emoji = '‚ùå'
            status_message = "Sistema requiere correcciones antes del entrenamiento"
        
        print(f"{status_emoji} Estado General: {test_results['overall_status']}")
        print(f"   {status_message}")
        print(f"   Errores: {error_count}")
        print(f"   Advertencias: {warning_count}")
        
        # Mostrar errores si los hay
        if test_results['errors']:
            print("\n‚ùå ERRORES ENCONTRADOS:")
            for i, error in enumerate(test_results['errors'], 1):
                print(f"   {i}. {error}")
        
        # Mostrar advertencias si las hay
        if test_results['warnings']:
            print("\n‚ö†Ô∏è ADVERTENCIAS:")
            for i, warning in enumerate(test_results['warnings'], 1):
                print(f"   {i}. {warning}")
        
        # Generar recomendaciones
        if test_results['overall_status'] in ['EXCELLENT', 'GOOD']:
            test_results['recommendations'].append("‚úÖ El sistema est√° listo para entrenamiento completo")
            if enhanced_trainer.system_version == 'enhanced':
                test_results['recommendations'].append("üéØ Considera usar 3-5M timesteps para mejores resultados")
                test_results['recommendations'].append("üí™ El sistema antag√≥nico deber√≠a mostrar movimientos m√°s naturales")
        
        if warning_count > 0:
            test_results['recommendations'].append("üîß Revisa las advertencias antes del entrenamiento largo")
        
        # Mostrar recomendaciones
        if test_results['recommendations']:
            print("\nüí° RECOMENDACIONES:")
            for i, rec in enumerate(test_results['recommendations'], 1):
                print(f"   {i}. {rec}")
        
        print("\n" + "=" * 70)
        print("Test de integraci√≥n completado. El sistema est√° listo para uso!")
        
        return test_results
        
    except Exception as e:
        test_results['errors'].append(f"Critical test failure: {str(e)}")
        test_results['overall_status'] = 'CRITICAL_FAILURE'
        print(f"\nüí• Error cr√≠tico durante el testing: {e}")
        import traceback
        traceback.print_exc()
        return test_results