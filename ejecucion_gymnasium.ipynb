{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75871c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inicio_programa import train_balance_pure_rl\n",
    "\n",
    "train_balance_pure_rl(total_timesteps=800000, n_envs=8, with_logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c48489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inicio_programa import train_balance_march_in_place\n",
    "\n",
    "train_balance_march_in_place(total_timesteps=800000, n_envs=8, with_logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afa8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Logging directory: ./logs_lift_leg\n",
      "ðŸŽ¯ PURE RL BALANCE TRAINING\n",
      "============================================================\n",
      "Objetivo especÃ­fico:\n",
      "  âœ… Mantener equilibrio bÃ¡sico de pie\n",
      "  âœ… Sin ayuda experta (assist=0)\n",
      "  âœ… Sin progression de niveles\n",
      "  âœ… RL puro - el modelo aprende solo\n",
      "============================================================\n",
      "ðŸ¤– Trainer ready\n",
      "âœ… Trainer created (NO CURRICULUM)\n",
      "   Focus: Balance bÃ¡sico con RL puro\n",
      "   Expert help: 0% (assist=0 siempre)\n",
      "   Architecture: RecurrentPPO with 128 LSTM units\n",
      "ðŸš€ Starting lift_leg training with RecurrentPPO...\n",
      "ðŸ“Š Training plan:\n",
      "   Completed: 0\n",
      "   Remaining: 2,500,000\n",
      "   Total target: 2,500,000\n",
      "ðŸ§  Creating new RecurrentPPO model for lift_leg...\n",
      "Using cuda device\n",
      "âœ… Model created with 128 LSTM units\n",
      "Logging to ./logs_lift_leg\\Walker_6DOF_3D_training_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 56.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.9        |\n",
      "|    ep_rew_mean          | 68.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009076065 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.1       |\n",
      "|    explained_variance   | 0.00639     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.364      |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.714       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010256624 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.2       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0589      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 158          |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117582595 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -17.2        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.351       |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0763       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 131         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011384886 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.3       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0655      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 243        |\n",
      "|    ep_rew_mean          | 166        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01102111 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -17.4      |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.348     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.06       |\n",
      "----------------------------------------\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=50000, episode_reward=245.78 +/- 96.17\n",
      "Episode length: 352.10 +/- 141.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 352         |\n",
      "|    mean_reward          | 246         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011717083 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.5       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.371      |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.058       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 186      |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 392      |\n",
      "|    total_timesteps | 57344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | 202         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698377 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.5       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.357      |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 318          |\n",
      "|    ep_rew_mean          | 220          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 474          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107721435 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -17.6        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.375       |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0254       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 335       |\n",
      "|    ep_rew_mean          | 231       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 158       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 515       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0106433 |\n",
      "|    clip_fraction        | 0.113     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -17.7     |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.376    |\n",
      "|    n_updates            | 36        |\n",
      "|    policy_gradient_loss | -0.00955  |\n",
      "|    std                  | 1.06      |\n",
      "|    value_loss           | 0.0211    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 239         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011723961 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.361      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 367        |\n",
      "|    ep_rew_mean          | 256        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 597        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01096076 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -17.9      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.375     |\n",
      "|    n_updates            | 44         |\n",
      "|    policy_gradient_loss | -0.0089    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0388     |\n",
      "----------------------------------------\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=100000, episode_reward=335.90 +/- 132.22\n",
      "Episode length: 476.70 +/- 189.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 477         |\n",
      "|    mean_reward          | 336         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011202043 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18         |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.383      |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0278      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "ðŸ’¾ Saved VecNormalize at 100000 steps -> ./models_lift_leg\\checkpoints\\Walker_6DOF_3D_normalize_100000_steps.pkl\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 383      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    fps             | 160      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 663      |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 389        |\n",
      "|    ep_rew_mean          | 273        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 163        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 701        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106896 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -18        |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.363     |\n",
      "|    n_updates            | 52         |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.02       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 387          |\n",
      "|    ep_rew_mean          | 272          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 165          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 741          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124822045 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -18.1        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.387       |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.0193       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 408         |\n",
      "|    ep_rew_mean          | 288         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 168         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 776         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012542263 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.2       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.389      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0171      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 412         |\n",
      "|    ep_rew_mean          | 288         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 813         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012538653 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.2       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.372      |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0183      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 173         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 850         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013557842 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.387      |\n",
      "|    n_updates            | 68          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=150000, episode_reward=292.80 +/- 143.25\n",
      "Episode length: 415.20 +/- 202.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 415         |\n",
      "|    mean_reward          | 293         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012582942 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.371      |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0174      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 422      |\n",
      "|    ep_rew_mean     | 294      |\n",
      "| time/              |          |\n",
      "|    fps             | 169      |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 917      |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 451         |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014401268 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.412      |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 458         |\n",
      "|    ep_rew_mean          | 320         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013088017 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.399      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0183      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 476         |\n",
      "|    ep_rew_mean          | 335         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 177         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1017        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018233925 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.384      |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0271      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 495         |\n",
      "|    ep_rew_mean          | 351         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012922958 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.377      |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0321      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 512         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013395745 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.369      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.0196      |\n",
      "-----------------------------------------\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "ðŸ”„ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=200000, episode_reward=424.69 +/- 146.29\n",
      "Episode length: 594.60 +/- 203.27\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 595        |\n",
      "|    mean_reward          | 425        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 200000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01447615 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -18.8      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.371     |\n",
      "|    n_updates            | 96         |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 0.0259     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "ðŸ’¾ Saved VecNormalize at 200000 steps -> ./models_lift_leg\\checkpoints\\Walker_6DOF_3D_normalize_200000_steps.pkl\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 534      |\n",
      "|    ep_rew_mean     | 382      |\n",
      "| time/              |          |\n",
      "|    fps             | 178      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1148     |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from inicio_programa import train_balance_walk_3d\n",
    "\n",
    "train_balance_walk_3d(total_timesteps=2500000, n_envs=8, \n",
    "                      with_logger=True, robot_name=\"2_legged_human_like_robot12DOF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GymnasiumBipedRobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
