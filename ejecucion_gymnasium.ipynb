{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75871c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inicio_programa import train_balance_pure_rl\n",
    "\n",
    "train_balance_pure_rl(total_timesteps=800000, n_envs=8, with_logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c48489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inicio_programa import train_balance_march_in_place\n",
    "\n",
    "train_balance_march_in_place(total_timesteps=800000, n_envs=8, with_logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70afa8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Logging directory: ./logs_lift_leg\n",
      "üéØ PURE RL BALANCE TRAINING\n",
      "============================================================\n",
      "Objetivo espec√≠fico:\n",
      "  ‚úÖ Mantener equilibrio b√°sico de pie\n",
      "  ‚úÖ Sin ayuda experta (assist=0)\n",
      "  ‚úÖ Sin progression de niveles\n",
      "  ‚úÖ RL puro - el modelo aprende solo\n",
      "============================================================\n",
      "ü§ñ Trainer ready\n",
      "‚úÖ Trainer created (NO CURRICULUM)\n",
      "   Focus: Balance b√°sico con RL puro\n",
      "   Expert help: 0% (assist=0 siempre)\n",
      "   Architecture: RecurrentPPO with 128 LSTM units\n",
      "üöÄ Starting lift_leg training with RecurrentPPO...\n",
      "üìä Training plan:\n",
      "   Completed: 0\n",
      "   Remaining: 1,800,000\n",
      "   Total target: 1,800,000\n",
      "{'2_legged_human_like_robot12DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot12DOF.urdf', '2_legged_human_like_robot12DOFdone_2': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot12DOFdone_2.urdf', '2_legged_human_like_robot12DOF_done': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot12DOF_done.urdf', '2_legged_human_like_robot16DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot16DOF.urdf', '2_legged_human_like_robot20DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot20DOF.urdf', '2_legged_human_like_robot24DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\2_legged_human_like_robot24DOF.urdf', 'Black_bird': None, 'cassie_description': None, 'Robots_Rodilla_Invertida': None} {'2_legged_human_like_robot12DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\JSON_Info_Robot\\\\2_legged_human_like_robot12DOF.json', '2_legged_human_like_robot12DOFdone_2': None, '2_legged_human_like_robot12DOF_done': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\JSON_Info_Robot\\\\2_legged_human_like_robot12DOF_done.json', '2_legged_human_like_robot16DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\JSON_Info_Robot\\\\2_legged_human_like_robot16DOF.json', '2_legged_human_like_robot20DOF': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\JSON_Info_Robot\\\\2_legged_human_like_robot20DOF.json', '2_legged_human_like_robot24DOF': None, 'Black_bird': None, 'cassie_description': None, 'Robots_Rodilla_Invertida': None, 'blackbird': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\JSON_Info_Robot\\\\blackbird.json', 'top_level': 'C:\\\\Users\\\\Alejandro\\\\Documents\\\\Master_IA\\\\TFM\\\\soft_robots\\\\programacion_soft_robotic\\\\Marcha_IK\\\\Robots_Versiones\\\\Black_bird\\\\urdf\\\\top_level.txt'}\n",
      "2_legged_human_like_robot12DOF_done C:\\Users\\Alejandro\\Documents\\Master_IA\\TFM\\soft_robots\\programacion_soft_robotic\\Marcha_IK\\Robots_Versiones\\2_legged_human_like_robot12DOF_done.urdf\n",
      "['left_hip_pitch_joint_flexor', 'left_hip_pitch_joint_extensor', 'left_knee_joint_flexor', 'left_knee_joint_extensor', 'left_ankle_pitch_joint_flexor', 'left_ankle_pitch_joint_extensor', 'right_hip_pitch_joint_flexor', 'right_hip_pitch_joint_extensor', 'right_knee_joint_flexor', 'right_knee_joint_extensor', 'right_ankle_pitch_joint_flexor', 'right_ankle_pitch_joint_extensor']\n",
      "üß† Creating new RecurrentPPO model for lift_leg...\n",
      "Using cuda device\n",
      "‚úÖ Model created with 128 LSTM units\n",
      "Logging to ./logs_lift_leg\\Walker_6DOF_3D_training_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 134      |\n",
      "|    ep_rew_mean     | -17.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 465      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 157        |\n",
      "|    ep_rew_mean          | -27.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00306394 |\n",
      "|    clip_fraction        | 0.0242     |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -17.1      |\n",
      "|    explained_variance   | -0.0763    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.14       |\n",
      "|    n_updates            | 4          |\n",
      "|    policy_gradient_loss | -0.0042    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.546      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 193          |\n",
      "|    ep_rew_mean          | -84          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 177          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040127845 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.1        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.169       |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.041        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 229          |\n",
      "|    ep_rew_mean          | -124         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 169          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036322544 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.2        |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.177       |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0563       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 254          |\n",
      "|    ep_rew_mean          | -151         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036002647 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.2        |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.175       |\n",
      "|    n_updates            | 16           |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0348       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 289          |\n",
      "|    ep_rew_mean          | -214         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048187785 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.2        |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.18        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0384       |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=50000, episode_reward=78.51 +/- 143.26\n",
      "Episode length: 239.80 +/- 81.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 240          |\n",
      "|    mean_reward          | 78.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043933108 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.2        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.16        |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0342       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 297      |\n",
      "|    ep_rew_mean     | -161     |\n",
      "| time/              |          |\n",
      "|    fps             | 154      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 57344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004605295 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.3       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.174      |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0328      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 205          |\n",
      "|    ep_rew_mean          | -0.43        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 484          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053828913 |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.3        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.181       |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | -0.00882     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0264       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 217          |\n",
      "|    ep_rew_mean          | -0.764       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048892824 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.3        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.185       |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0176       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 212          |\n",
      "|    ep_rew_mean          | 81.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 593          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056103086 |\n",
      "|    clip_fraction        | 0.0922       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.3        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.187       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0198       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 222          |\n",
      "|    ep_rew_mean          | 112          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 644          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051233685 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.3        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.182       |\n",
      "|    n_updates            | 44           |\n",
      "|    policy_gradient_loss | -0.00962     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00871      |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=100000, episode_reward=105.49 +/- 203.05\n",
      "Episode length: 262.00 +/- 136.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 262         |\n",
      "|    mean_reward          | 105         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005661928 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.4       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.187      |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00627     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 224      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    fps             | 151      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 704      |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 251          |\n",
      "|    ep_rew_mean          | 155          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 756          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064452337 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.4        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.19        |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0158       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 276         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005855988 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.4       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.189      |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00771     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 205          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 860          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049002925 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.4        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.186       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00446      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 293          |\n",
      "|    ep_rew_mean          | 221          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 906          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057532266 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.4        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.2         |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00553      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 299          |\n",
      "|    ep_rew_mean          | 229          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 955          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060793087 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.5        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.193       |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00547      |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=150000, episode_reward=108.20 +/- 278.09\n",
      "Episode length: 290.00 +/- 80.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 290         |\n",
      "|    mean_reward          | 108         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005915125 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.5       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.186      |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00386     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 215      |\n",
      "| time/              |          |\n",
      "|    fps             | 153      |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 1011     |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 315          |\n",
      "|    ep_rew_mean          | 226          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1060         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059524453 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.5        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.183       |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00888      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 241         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1114        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006126937 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.5       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.189      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00372     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 333          |\n",
      "|    ep_rew_mean          | 257          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1164         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052796565 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.5        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.19        |\n",
      "|    n_updates            | 84           |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00407      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 254         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005432737 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.5       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.006       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 289          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1271         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051537897 |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.6        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.196       |\n",
      "|    n_updates            | 92           |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00927      |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=200000, episode_reward=230.56 +/- 147.98\n",
      "Episode length: 409.40 +/- 142.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 409          |\n",
      "|    mean_reward          | 231          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058530206 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.6        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.161       |\n",
      "|    n_updates            | 96           |\n",
      "|    policy_gradient_loss | -0.009       |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0104       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 370      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    fps             | 153      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1332     |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 372        |\n",
      "|    ep_rew_mean          | 282        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 1383       |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00633318 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -17.6      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.191     |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00926   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0116     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 363          |\n",
      "|    ep_rew_mean          | 302          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1439         |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061250296 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.6        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.184       |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00797     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0059       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | 290         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1496        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005824856 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.6       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.188      |\n",
      "|    n_updates            | 108         |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00365     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | 299         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009186566 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.6       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.023       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | 317         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1597        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007046096 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.6       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.186      |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=250000, episode_reward=23.60 +/- 552.64\n",
      "Episode length: 694.00 +/- 215.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 694         |\n",
      "|    mean_reward          | 23.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007022735 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.6       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.184      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0246      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 440      |\n",
      "|    ep_rew_mean     | 343      |\n",
      "| time/              |          |\n",
      "|    fps             | 152      |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 1663     |\n",
      "|    total_timesteps | 253952   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 475          |\n",
      "|    ep_rew_mean          | 353          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1710         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061673876 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.7        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.195       |\n",
      "|    n_updates            | 124          |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.0113       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 496         |\n",
      "|    ep_rew_mean          | 341         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864455 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.7       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.165      |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 538         |\n",
      "|    ep_rew_mean          | 354         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007867155 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.7       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.179      |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0194      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 561         |\n",
      "|    ep_rew_mean          | 386         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1847        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006418056 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.7       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.195      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.03        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | 387          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1891         |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072887633 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.7        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.187       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.0162       |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=300000, episode_reward=827.52 +/- 486.58\n",
      "Episode length: 780.20 +/- 350.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 780         |\n",
      "|    mean_reward          | 828         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007174449 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.174      |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 628      |\n",
      "|    ep_rew_mean     | 430      |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 1950     |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 647         |\n",
      "|    ep_rew_mean          | 493         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1986        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007432172 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.177      |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | 514          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 2032         |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066984706 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.8        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.186       |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.00536      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | 483         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 2069        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008206153 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00901     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | 540         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2110        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008418284 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.163      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0533      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 765         |\n",
      "|    ep_rew_mean          | 524         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008452174 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.8       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.186      |\n",
      "|    n_updates            | 164         |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0153      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=350000, episode_reward=493.78 +/- 245.27\n",
      "Episode length: 566.40 +/- 75.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 566          |\n",
      "|    mean_reward          | 494          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071040066 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -17.9        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.201       |\n",
      "|    n_updates            | 168          |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.032        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 753      |\n",
      "|    ep_rew_mean     | 496      |\n",
      "| time/              |          |\n",
      "|    fps             | 159      |\n",
      "|    iterations      | 43       |\n",
      "|    time_elapsed    | 2204     |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 739         |\n",
      "|    ep_rew_mean          | 484         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 2256        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006691403 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.9       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0282      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2301        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007416471 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -17.9       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.198      |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 713          |\n",
      "|    ep_rew_mean          | 467          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 2348         |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067489115 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18          |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.193       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00957     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.0186       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 385         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 2385        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013474255 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18         |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.18       |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0364      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 692         |\n",
      "|    ep_rew_mean          | 394         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 2432        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182485 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18         |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.187      |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0224      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=400000, episode_reward=525.07 +/- 279.48\n",
      "Episode length: 898.40 +/- 554.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 898          |\n",
      "|    mean_reward          | 525          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062677925 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18          |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.185       |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.0124       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 658      |\n",
      "|    ep_rew_mean     | 357      |\n",
      "| time/              |          |\n",
      "|    fps             | 160      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 2503     |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 630          |\n",
      "|    ep_rew_mean          | 401          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 2554         |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077863773 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18          |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.185       |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00912      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 654          |\n",
      "|    ep_rew_mean          | 437          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 2598         |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067305164 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.1        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.193       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.0151       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 659         |\n",
      "|    ep_rew_mean          | 451         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 2644        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007947665 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.1       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | 509         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 2681        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007970286 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.1       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00955     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 703          |\n",
      "|    ep_rew_mean          | 551          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 2722         |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075711035 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.1        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.201       |\n",
      "|    n_updates            | 212          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.00582      |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=450000, episode_reward=333.21 +/- 1157.76\n",
      "Episode length: 972.00 +/- 473.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 972         |\n",
      "|    mean_reward          | 333         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009698275 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.2       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.195      |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00266     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 708      |\n",
      "|    ep_rew_mean     | 606      |\n",
      "| time/              |          |\n",
      "|    fps             | 161      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 2784     |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 714          |\n",
      "|    ep_rew_mean          | 624          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 2826         |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087030195 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.2        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.194       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.0131       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 722          |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 2867         |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091520455 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.2        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.197       |\n",
      "|    n_updates            | 224          |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.015        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 759          |\n",
      "|    ep_rew_mean          | 730          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 163          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 2906         |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077462485 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.2        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.2         |\n",
      "|    n_updates            | 228          |\n",
      "|    policy_gradient_loss | -0.00909     |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.0101       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 778         |\n",
      "|    ep_rew_mean          | 779         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 2954        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009563194 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.2       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.198      |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00443     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 786         |\n",
      "|    ep_rew_mean          | 812         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 3000        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010935532 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.193      |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 777         |\n",
      "|    ep_rew_mean          | 835         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 3050        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008289939 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.204      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.003       |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=500000, episode_reward=944.56 +/- 320.18\n",
      "Episode length: 770.00 +/- 268.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 770        |\n",
      "|    mean_reward          | 945        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 500000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00787618 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -18.3      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.187     |\n",
      "|    n_updates            | 244        |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.00264    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 771      |\n",
      "|    ep_rew_mean     | 835      |\n",
      "| time/              |          |\n",
      "|    fps             | 163      |\n",
      "|    iterations      | 62       |\n",
      "|    time_elapsed    | 3103     |\n",
      "|    total_timesteps | 507904   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 762         |\n",
      "|    ep_rew_mean          | 802         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 3141        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012213444 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.00447     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 766         |\n",
      "|    ep_rew_mean          | 757         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 3176        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008671049 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.161      |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 795          |\n",
      "|    ep_rew_mean          | 800          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 165          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 3210         |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075780107 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.3        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.202       |\n",
      "|    n_updates            | 256          |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.0223       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 832         |\n",
      "|    ep_rew_mean          | 845         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 3241        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008480917 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.3       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0078      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 831         |\n",
      "|    ep_rew_mean          | 862         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 3279        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474587 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.00802     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=550000, episode_reward=597.27 +/- 321.37\n",
      "Episode length: 500.60 +/- 205.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 501         |\n",
      "|    mean_reward          | 597         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010844961 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0068      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 844      |\n",
      "|    ep_rew_mean     | 851      |\n",
      "| time/              |          |\n",
      "|    fps             | 167      |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 3327     |\n",
      "|    total_timesteps | 557056   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 859         |\n",
      "|    ep_rew_mean          | 864         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 168         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 3362        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011598964 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.184      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0347      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 887         |\n",
      "|    ep_rew_mean          | 879         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 3390        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010173162 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.00316     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 911         |\n",
      "|    ep_rew_mean          | 882         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 169         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 3429        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010167511 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.16       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 942         |\n",
      "|    ep_rew_mean          | 902         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 3463        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009011912 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.193      |\n",
      "|    n_updates            | 284         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.00994     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 948         |\n",
      "|    ep_rew_mean          | 910         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 3507        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203791 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.4       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.213      |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.00583     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=600000, episode_reward=1455.58 +/- 625.71\n",
      "Episode length: 1356.00 +/- 572.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | 1.46e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009206182 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.198      |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.00617     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 964      |\n",
      "|    ep_rew_mean     | 897      |\n",
      "| time/              |          |\n",
      "|    fps             | 169      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 3570     |\n",
      "|    total_timesteps | 606208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 989         |\n",
      "|    ep_rew_mean          | 935         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 3609        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012659913 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 999         |\n",
      "|    ep_rew_mean          | 957         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 3637        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010251921 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.201      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.04e+03   |\n",
      "|    ep_rew_mean          | 1.02e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 172        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 3659       |\n",
      "|    total_timesteps      | 630784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01152357 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -18.5      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.211     |\n",
      "|    n_updates            | 304        |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 0.00396    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.06e+03   |\n",
      "|    ep_rew_mean          | 1.04e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 173        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 3690       |\n",
      "|    total_timesteps      | 638976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826359 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -18.6      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.199     |\n",
      "|    n_updates            | 308        |\n",
      "|    policy_gradient_loss | -0.00554   |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 0.00868    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 173         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 3720        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009318545 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0039      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=650000, episode_reward=1068.67 +/- 684.27\n",
      "Episode length: 1070.60 +/- 710.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | 1.07e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009200032 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.198      |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.00436     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 1.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 173      |\n",
      "|    iterations      | 80       |\n",
      "|    time_elapsed    | 3772     |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 1.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 3808        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009213072 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.188      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.00654     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 175         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 3831        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009768165 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0017      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 1.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 175         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 3863        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009830739 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 176         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 3906        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010543928 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.00339     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 176         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 3934        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008876521 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.19       |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0021      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=700000, episode_reward=1191.00 +/- 695.59\n",
      "Episode length: 1222.20 +/- 655.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 1.19e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010015095 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.6       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.00349     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.15e+03 |\n",
      "|    ep_rew_mean     | 1.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 177      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 3979     |\n",
      "|    total_timesteps | 704512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 177         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 4010        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011555732 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | 1.24e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 4039         |\n",
      "|    total_timesteps      | 720896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067157103 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.7        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.199       |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.00996     |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 0.00529      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 4074        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008255875 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 352         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0034      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 179         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 4108        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010400454 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 356         |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0146      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 180         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 4132        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009843275 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.213      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0031      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=750000, episode_reward=1908.36 +/- 787.60\n",
      "Episode length: 1516.00 +/- 504.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | 1.91e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009088738 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.22e+03 |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 179      |\n",
      "|    iterations      | 92       |\n",
      "|    time_elapsed    | 4205     |\n",
      "|    total_timesteps | 753664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 180         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 4227        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008558752 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 180         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 4259        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009339424 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.00291     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 181        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 4291       |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00983222 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -18.8      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.206     |\n",
      "|    n_updates            | 376        |\n",
      "|    policy_gradient_loss | -0.00934   |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 0.00465    |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.2e+03  |\n",
      "|    ep_rew_mean          | 1.31e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 182      |\n",
      "|    iterations           | 96       |\n",
      "|    time_elapsed         | 4318     |\n",
      "|    total_timesteps      | 786432   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.008097 |\n",
      "|    clip_fraction        | 0.172    |\n",
      "|    clip_range           | 0.15     |\n",
      "|    entropy_loss         | -18.8    |\n",
      "|    explained_variance   | 0.983    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.21    |\n",
      "|    n_updates            | 380      |\n",
      "|    policy_gradient_loss | -0.00986 |\n",
      "|    std                  | 1.16     |\n",
      "|    value_loss           | 0.00155  |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 4357        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010900822 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.16       |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=800000, episode_reward=1550.36 +/- 1006.01\n",
      "Episode length: 1264.20 +/- 810.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.26e+03     |\n",
      "|    mean_reward          | 1.55e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077782087 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.9        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.203       |\n",
      "|    n_updates            | 388          |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 1.17         |\n",
      "|    value_loss           | 0.00428      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.25e+03 |\n",
      "|    ep_rew_mean     | 1.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 182      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 4403     |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 4437        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011178823 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.215      |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 183         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 4459        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664988 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.19       |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.0366      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | 1.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 184          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 4495         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076185535 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.9        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.199       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00827     |\n",
      "|    std                  | 1.17         |\n",
      "|    value_loss           | 0.006        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 4519        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011461656 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 185         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 4552        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012020705 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.202      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.00329     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=850000, episode_reward=871.97 +/- 531.31\n",
      "Episode length: 823.80 +/- 615.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 824          |\n",
      "|    mean_reward          | 872          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114333145 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -18.9        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.187       |\n",
      "|    n_updates            | 412          |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    std                  | 1.17         |\n",
      "|    value_loss           | 0.0175       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 185      |\n",
      "|    iterations      | 104      |\n",
      "|    time_elapsed    | 4599     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 185         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 4629        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016834646 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.189      |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.00663     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 4652        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010705955 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.201      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.00703     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 4689        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011819486 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.182      |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.00792     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 4723        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015649581 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.202      |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.00375     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 4760        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012805147 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.201      |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.0056      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=900000, episode_reward=1032.45 +/- 895.68\n",
      "Episode length: 840.00 +/- 653.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 840         |\n",
      "|    mean_reward          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009914452 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.195      |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.0064      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 187      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 4802     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 4840        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009290108 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19         |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.222      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.00986     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.36e+03   |\n",
      "|    ep_rew_mean          | 1.5e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 188        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 4864       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01488031 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.1      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.203     |\n",
      "|    n_updates            | 444        |\n",
      "|    policy_gradient_loss | -0.00763   |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 0.00572    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.4e+03    |\n",
      "|    ep_rew_mean          | 1.58e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 189        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 4888       |\n",
      "|    total_timesteps      | 925696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01056237 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.1      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.21      |\n",
      "|    n_updates            | 448        |\n",
      "|    policy_gradient_loss | -0.00529   |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 0.0044     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.38e+03   |\n",
      "|    ep_rew_mean          | 1.57e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 189        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 4920       |\n",
      "|    total_timesteps      | 933888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01118908 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.1      |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.2       |\n",
      "|    n_updates            | 452        |\n",
      "|    policy_gradient_loss | -0.00746   |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 0.00798    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.38e+03   |\n",
      "|    ep_rew_mean          | 1.6e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 190        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 4941       |\n",
      "|    total_timesteps      | 942080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00971013 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.1      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.207     |\n",
      "|    n_updates            | 456        |\n",
      "|    policy_gradient_loss | -0.0088    |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 0.0025     |\n",
      "----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=950000, episode_reward=1875.96 +/- 1109.35\n",
      "Episode length: 1376.40 +/- 775.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | 1.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009978928 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.1       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.209      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | 1.66e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 189      |\n",
      "|    iterations      | 116      |\n",
      "|    time_elapsed    | 5010     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 1.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 190         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 5034        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011316022 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.1       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.19       |\n",
      "|    n_updates            | 464         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.00481     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.39e+03  |\n",
      "|    ep_rew_mean          | 1.67e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 190       |\n",
      "|    iterations           | 118       |\n",
      "|    time_elapsed         | 5066      |\n",
      "|    total_timesteps      | 966656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0081538 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -19.1     |\n",
      "|    explained_variance   | 0.94      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.205    |\n",
      "|    n_updates            | 468       |\n",
      "|    policy_gradient_loss | -0.00973  |\n",
      "|    std                  | 1.19      |\n",
      "|    value_loss           | 0.00707   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 1.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 191         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 5100        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011241725 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 472         |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.00531     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 1.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 191         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 5137        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010027386 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.221      |\n",
      "|    n_updates            | 476         |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 5158        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010301409 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.00316     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.35e+03  |\n",
      "|    ep_rew_mean          | 1.72e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 192       |\n",
      "|    iterations           | 122       |\n",
      "|    time_elapsed         | 5190      |\n",
      "|    total_timesteps      | 999424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0112027 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -19.2     |\n",
      "|    explained_variance   | 0.907     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.207    |\n",
      "|    n_updates            | 484       |\n",
      "|    policy_gradient_loss | -0.00751  |\n",
      "|    std                  | 1.2       |\n",
      "|    value_loss           | 0.00852   |\n",
      "---------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1000000, episode_reward=392.07 +/- 213.72\n",
      "Episode length: 433.20 +/- 163.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 433         |\n",
      "|    mean_reward          | 392         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010010652 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 488         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.00118     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | 1.78e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 193      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 5220     |\n",
      "|    total_timesteps | 1007616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 1.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 5252        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012405815 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 492         |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 1.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 5279        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010944964 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.2       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.195      |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.00625     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 5305        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011447412 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.188      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00769     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 5329        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008552199 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 504         |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00488     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 1.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 5356        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008143507 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.203      |\n",
      "|    n_updates            | 508         |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00997     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1050000, episode_reward=1848.97 +/- 1179.71\n",
      "Episode length: 1346.60 +/- 806.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | 1.85e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010318366 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.201      |\n",
      "|    n_updates            | 512         |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00823     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.41e+03 |\n",
      "|    ep_rew_mean     | 1.93e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 195      |\n",
      "|    iterations      | 129      |\n",
      "|    time_elapsed    | 5413     |\n",
      "|    total_timesteps | 1056768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 5436        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918134 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.183      |\n",
      "|    n_updates            | 516         |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00702     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 1.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 5460        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010892257 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00853     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 2.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 5486        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010681085 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 524         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00757     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 5516        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009629471 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.00953     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 2.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 5538        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008017662 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.3       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.207      |\n",
      "|    n_updates            | 532         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.00494     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1100000, episode_reward=1375.34 +/- 1273.02\n",
      "Episode length: 1008.80 +/- 810.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009382157 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.218      |\n",
      "|    n_updates            | 536         |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.00766     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.5e+03  |\n",
      "|    ep_rew_mean     | 2.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 197      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 5587     |\n",
      "|    total_timesteps | 1105920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 2.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 5606        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011859348 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.194      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.0082      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 5634        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110384 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 544         |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 2.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 5657        |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009880645 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.202      |\n",
      "|    n_updates            | 548         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 5685        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016146526 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.00702     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 2.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 5711        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010424612 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.4       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.00367     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1150000, episode_reward=2330.60 +/- 1012.75\n",
      "Episode length: 1658.20 +/- 683.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.66e+03   |\n",
      "|    mean_reward          | 2.33e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1150000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01133258 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.4      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.2       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.00762   |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 0.00598    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 2.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 200      |\n",
      "|    iterations      | 141      |\n",
      "|    time_elapsed    | 5773     |\n",
      "|    total_timesteps | 1155072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 2.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 5807        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009073329 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 564         |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.0118      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 5831        |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009471542 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 568         |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.0063      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 5859        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010698838 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 572         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.00836     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 5884        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012423871 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 2.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 5909        |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009216184 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.00679     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1200000, episode_reward=2933.24 +/- 45.41\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.93e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010379158 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 584         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.00542     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | 2.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 201      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 5987     |\n",
      "|    total_timesteps | 1204224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 2.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 6008        |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013502713 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.209      |\n",
      "|    n_updates            | 588         |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.00709     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 2.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 6036        |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009521907 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.21       |\n",
      "|    n_updates            | 592         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.00485     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 6059        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010471163 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.5       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.00569     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 6084        |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010942202 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.203      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.00633     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 6108        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010707869 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.203      |\n",
      "|    n_updates            | 604         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.00698     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1250000, episode_reward=2412.90 +/- 1029.61\n",
      "Episode length: 1663.20 +/- 673.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | 2.41e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010335894 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 608         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.00366     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.54e+03 |\n",
      "|    ep_rew_mean     | 2.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 203      |\n",
      "|    iterations      | 153      |\n",
      "|    time_elapsed    | 6172     |\n",
      "|    total_timesteps | 1253376  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | 2.15e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 203        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 6200       |\n",
      "|    total_timesteps      | 1261568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00954413 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.6      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.212     |\n",
      "|    n_updates            | 612        |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 0.00368    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 6226        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009618796 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.194      |\n",
      "|    n_updates            | 616         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 6257        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009192814 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.00701     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 2.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 6282        |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012688812 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.6       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.224      |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.00772     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.63e+03  |\n",
      "|    ep_rew_mean          | 2.29e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 205       |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 6310      |\n",
      "|    total_timesteps      | 1294336   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0083682 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.15      |\n",
      "|    entropy_loss         | -19.7     |\n",
      "|    explained_variance   | 0.954     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.214    |\n",
      "|    n_updates            | 628       |\n",
      "|    policy_gradient_loss | -0.00844  |\n",
      "|    std                  | 1.25      |\n",
      "|    value_loss           | 0.00229   |\n",
      "---------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1300000, episode_reward=2944.13 +/- 60.41\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.94e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013018206 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.7       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 632         |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.00668     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | 2.32e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 203      |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 6385     |\n",
      "|    total_timesteps | 1302528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | 2.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 6407        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010655182 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.7       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.208      |\n",
      "|    n_updates            | 636         |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.00551     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | 2.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 6435        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009524543 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.7       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.162      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.00643     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 2.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 6460        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010722346 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.7       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.209      |\n",
      "|    n_updates            | 644         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.00654     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 6484        |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012304732 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.8       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.218      |\n",
      "|    n_updates            | 648         |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.00472     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 6507        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404031 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.8       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.213      |\n",
      "|    n_updates            | 652         |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.00526     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1350000, episode_reward=1877.15 +/- 1174.96\n",
      "Episode length: 1377.20 +/- 762.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | 1.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010092915 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.8       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.78e+03 |\n",
      "|    ep_rew_mean     | 2.52e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 165      |\n",
      "|    time_elapsed    | 6561     |\n",
      "|    total_timesteps | 1351680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | 2.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 6588        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009909997 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.8       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.00741     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | 2.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 6612        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009165356 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.9       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 664         |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.00565     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 2.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 6641        |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010264928 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.9       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.217      |\n",
      "|    n_updates            | 668         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 2.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 6671        |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012257812 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.9       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.187      |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.84e+03   |\n",
      "|    ep_rew_mean          | 2.62e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 6695       |\n",
      "|    total_timesteps      | 1392640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01083268 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -19.9      |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.214     |\n",
      "|    n_updates            | 676        |\n",
      "|    policy_gradient_loss | -0.00987   |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 0.0079     |\n",
      "----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1400000, episode_reward=2878.87 +/- 61.51\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016587807 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -19.9       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.00614     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.8e+03  |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 207      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 6766     |\n",
      "|    total_timesteps | 1400832  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.8e+03      |\n",
      "|    ep_rew_mean          | 2.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 6787         |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094800275 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -19.9        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.21        |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 1.28         |\n",
      "|    value_loss           | 0.00259      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 6816        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177943 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.22       |\n",
      "|    n_updates            | 688         |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 6842        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012635893 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.22       |\n",
      "|    n_updates            | 692         |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.00875     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 6877        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018237937 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.21       |\n",
      "|    n_updates            | 696         |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | 2.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 6902        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010387259 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 0.00792     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 2.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 6932        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009953875 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.232      |\n",
      "|    n_updates            | 704         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1450000, episode_reward=2454.84 +/- 940.81\n",
      "Episode length: 1692.40 +/- 615.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.69e+03    |\n",
      "|    mean_reward          | 2.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011734182 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.1       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 708         |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 0.0062      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.64e+03 |\n",
      "|    ep_rew_mean     | 2.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 208      |\n",
      "|    iterations      | 178      |\n",
      "|    time_elapsed    | 7002     |\n",
      "|    total_timesteps | 1458176  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.64e+03   |\n",
      "|    ep_rew_mean          | 2.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 208        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 7029       |\n",
      "|    total_timesteps      | 1466368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568158 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -20.1      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.201     |\n",
      "|    n_updates            | 712        |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 0.00351    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | 2.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 7053        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013781967 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.1       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.213      |\n",
      "|    n_updates            | 716         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 0.00798     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 2.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 7079         |\n",
      "|    total_timesteps      | 1482752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102114715 |\n",
      "|    clip_fraction        | 0.229        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -20.1        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.23        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    std                  | 1.3          |\n",
      "|    value_loss           | 0.00482      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 7101        |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009187933 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.1       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.221      |\n",
      "|    n_updates            | 724         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.00386     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 2.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 7134        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011793476 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.1       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.226      |\n",
      "|    n_updates            | 728         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.00361     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1500000, episode_reward=1831.88 +/- 1268.44\n",
      "Episode length: 1425.00 +/- 720.33\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.42e+03   |\n",
      "|    mean_reward          | 1.83e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1500000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01143686 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -20.2      |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.213     |\n",
      "|    n_updates            | 732        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 0.00868    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | 2.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 209      |\n",
      "|    iterations      | 184      |\n",
      "|    time_elapsed    | 7192     |\n",
      "|    total_timesteps | 1507328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 7216        |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010845837 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 736         |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.00355     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 7243        |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011763214 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00519     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 7262        |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015816182 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 744         |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00342     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | 2.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 7287        |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009343527 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.217      |\n",
      "|    n_updates            | 748         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00489     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | 2.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 7309        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009667881 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 752         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00278     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1550000, episode_reward=2374.29 +/- 1042.97\n",
      "Episode length: 1665.80 +/- 668.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | 2.37e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013419932 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.212      |\n",
      "|    n_updates            | 756         |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.0072      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | 2.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 211      |\n",
      "|    iterations      | 190      |\n",
      "|    time_elapsed    | 7374     |\n",
      "|    total_timesteps | 1556480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | 2.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 7405        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028975185 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.116      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00964     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | 2.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 7426        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010612596 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 764         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.0038      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | 2.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 7457        |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008962966 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.21       |\n",
      "|    n_updates            | 768         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00387     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | 2.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 7480        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012358323 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.219      |\n",
      "|    n_updates            | 772         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | 2.42e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 212        |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 7517       |\n",
      "|    total_timesteps      | 1597440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01087036 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -20.3      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.216     |\n",
      "|    n_updates            | 776        |\n",
      "|    policy_gradient_loss | -0.00921   |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 0.00624    |\n",
      "----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1600000, episode_reward=2206.09 +/- 1415.33\n",
      "Episode length: 1702.20 +/- 595.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 2.21e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010788898 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.00231     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 2.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 211      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 7576     |\n",
      "|    total_timesteps | 1605632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 2.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 7611        |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014439776 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.214      |\n",
      "|    n_updates            | 784         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 2.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 7630        |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010165999 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.4       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.235      |\n",
      "|    n_updates            | 788         |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.00284     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.77e+03   |\n",
      "|    ep_rew_mean          | 2.5e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 212        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 7662       |\n",
      "|    total_timesteps      | 1630208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01792052 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.15       |\n",
      "|    entropy_loss         | -20.4      |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.218     |\n",
      "|    n_updates            | 792        |\n",
      "|    policy_gradient_loss | -0.00612   |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 0.0112     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 7687        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012390016 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.4       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.228      |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.00432     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 7714        |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535249 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.4       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.224      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.00511     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1650000, episode_reward=2424.33 +/- 1053.02\n",
      "Episode length: 1658.80 +/- 682.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | 2.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011783927 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.231      |\n",
      "|    n_updates            | 804         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.00352     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.79e+03 |\n",
      "|    ep_rew_mean     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 212      |\n",
      "|    iterations      | 202      |\n",
      "|    time_elapsed    | 7780     |\n",
      "|    total_timesteps | 1654784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 212         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 7810        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011424409 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.204      |\n",
      "|    n_updates            | 808         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 7836        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012367981 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.229      |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.00208     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 7864        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011070901 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.212      |\n",
      "|    n_updates            | 816         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.00938     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 7889        |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013278067 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.00839     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 7915        |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009646733 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.212      |\n",
      "|    n_updates            | 824         |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.00539     |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1700000, episode_reward=2951.70 +/- 30.62\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011761182 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.231      |\n",
      "|    n_updates            | 828         |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.00708     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.75e+03 |\n",
      "|    ep_rew_mean     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 213      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 7986     |\n",
      "|    total_timesteps | 1703936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 2.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 8014        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012292264 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 832         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.00701     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 8035        |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011619956 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 836         |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.0033      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 2.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 8062        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011214738 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.216      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.00559     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | 2.57e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 8081        |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010150589 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.213      |\n",
      "|    n_updates            | 844         |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.00335     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | 2.58e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 8108         |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104337465 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -20.6        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.219       |\n",
      "|    n_updates            | 848          |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    std                  | 1.35         |\n",
      "|    value_loss           | 0.0046       |\n",
      "------------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1750000, episode_reward=2956.42 +/- 23.26\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.96e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014314609 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 852         |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.00212     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.79e+03 |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 214      |\n",
      "|    iterations      | 214      |\n",
      "|    time_elapsed    | 8180     |\n",
      "|    total_timesteps | 1753088  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | 2.58e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 8212         |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124972435 |\n",
      "|    clip_fraction        | 0.217        |\n",
      "|    clip_range           | 0.15         |\n",
      "|    entropy_loss         | -20.6        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.209       |\n",
      "|    n_updates            | 856          |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    std                  | 1.36         |\n",
      "|    value_loss           | 0.00575      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | 2.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 8239        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012352764 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.222      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.00407     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | 2.63e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 8269        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010695951 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.7       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 864         |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.00787     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 2.66e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 8289        |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012020847 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.7       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.218      |\n",
      "|    n_updates            | 868         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.00414     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 2.66e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 8321        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012184622 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.7       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.222      |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "üîÑ Single leg balance environment reset - Ready for training\n",
      "Eval num_timesteps=1800000, episode_reward=2977.40 +/- 12.46\n",
      "Episode length: 2000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.98e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011121342 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.15        |\n",
      "|    entropy_loss         | -20.7       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.209      |\n",
      "|    n_updates            | 876         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.00305     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.87e+03 |\n",
      "|    ep_rew_mean     | 2.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 214      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 8389     |\n",
      "|    total_timesteps | 1802240  |\n",
      "---------------------------------\n",
      "‚úÖ Final model saved at: ./models_lift_leg\\Walker_6DOF_3D_final\n",
      "‚úÖ Normalization saved at: ./models_lift_leg\\Walker_6DOF_3D_normalize.pkl\n",
      "üíæ Training info saved: ./models_lift_leg\\Walker_6DOF_3D_info.json\n",
      "\n",
      "üéâ lift_leg training completed successfully!\n",
      "   Total timesteps: 1,800,000\n",
      "   Model saved in: ./models_lift_leg\n",
      "‚úÖ Training completed successfully!\n",
      "\n",
      "üéâ ¬°Entrenamiento RL puro completado!\n",
      "üìÅ Modelo guardado en: ./models_lift_leg\n",
      "üìä Logs disponibles en: ./logs_lift_leg\n",
      "ü§ñ El modelo aprendi√≥ sin ayuda experta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Gymnasium_Start.Simplified_Lift_Leg_Trainer.Simplified_Lift_Leg_Trainer at 0x2105e87aef0>,\n",
       " <sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x2105e878370>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inicio_programa import train_balance_walk_3d\n",
    "\n",
    "train_balance_walk_3d(total_timesteps=1800000, n_envs=8, \n",
    "                      with_logger=True, robot_name=\"2_legged_human_like_robot12DOF_done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GymnasiumRobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
